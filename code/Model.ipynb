{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm, tnrange, tqdm_notebook\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import utils\n",
    "import parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_senses_vocab_path = '../resources/semcor.vocab.WordNet.json'\n",
    "input_vocab_path = '../resources/semcor.input.vocab.json'\n",
    "input_antivocab_path = '../resources/semcor.leftout.vocab.json'\n",
    "\n",
    "# labels = '../resources/semcor.vocab.BabelNet.json'\n",
    "# labels = list(utils.json_vocab_reader(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "senses = utils.json_vocab_reader(fine_senses_vocab_path)\n",
    "inputs, antivocab = utils.json_vocab_reader(input_vocab_path, input_antivocab_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocab_merge(vocab1, vocab2):\n",
    "    \"\"\"\n",
    "    Merges two vocabularies into the first one, keeping the reverse vocabulary consistent.\n",
    "    :param vocab1: First vocabulary (will contain the merged vocabulary), as Dict str -> int\n",
    "    :param rev_vocab1: First reverse vocabulary, as List of str\n",
    "    :param vocab2: Second vocabulary, as Dict str -> int\n",
    "    :return: (vocab1, rev_vocab1) updated to resemble the merged vocabulary\n",
    "    \"\"\"\n",
    "\n",
    "    v1 = copy.deepcopy(vocab1)\n",
    "\n",
    "    for key2 in vocab2.keys():\n",
    "        if key2 not in v1:\n",
    "            v1[key2] = len(v1)\n",
    "\n",
    "    return v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_vocab = vocab_merge(senses, inputs)\n",
    "reverse_output_vocab =  dict((v, k) for k, v in output_vocab.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replacement_routine(l, entry):\n",
    "    ret_word = None\n",
    "    if l in antivocab:\n",
    "        ret_word = output_vocab[\"<REPLACEMENT>\"]\n",
    "\n",
    "    if entry.instance or ret_word is None:\n",
    "        if l in output_vocab:\n",
    "            ret_word = output_vocab[l]\n",
    "        elif ret_word is None:\n",
    "            ret_word = output_vocab[\"<UNK>\"]\n",
    "\n",
    "    return ret_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wn_id_from_synset(synset):\n",
    "    \"\"\"\n",
    "    Builds the WordNet ID in the shape of wn:<offset><pos> for the given synset.\n",
    "    :param synset: Synset to get the ID from\n",
    "    :return: WordNet ID as described\n",
    "    \"\"\"\n",
    "\n",
    "    offset = str(synset.offset())\n",
    "    offset = \"0\" * (8 - len(offset)) + offset  # append heading 0s to the offset\n",
    "    wn_id = \"wn:%s%s\" % (offset, synset.pos())\n",
    "\n",
    "    return wn_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def u_candidate_synsets(lemma, pos):\n",
    "    \"\"\"\n",
    "    Retrieves the candidate synsets for the given lemma and pos combination.\n",
    "    :param lemma: Lemma to get the synsets of\n",
    "    :param pos: POS associated to the lemma\n",
    "    :return: Candidate synsets having the given lemma and POS, as List; the lemma itself in case there is no match in WordNet\n",
    "    \"\"\"\n",
    "\n",
    "    pos_dictionary = {\"ADJ\": wn.ADJ, \"ADV\": wn.ADV, \"NOUN\": wn.NOUN, \"VERB\": wn.VERB}   # open classes only\n",
    "    if pos == \".\" or pos == \"PUNCT\":\n",
    "        return [\"<PUNCT>\"]\n",
    "    elif pos == \"NUM\":\n",
    "        return [\"<NUM>\"]\n",
    "    elif pos == \"SYM\":\n",
    "        return [\"<SYM>\"]\n",
    "    elif pos in pos_dictionary:\n",
    "        synsets = wn.synsets(lemma, pos=pos_dictionary[pos])\n",
    "    else:\n",
    "        synsets = wn.synsets(lemma)\n",
    "    #print(len(synsets))\n",
    "    if len(synsets) == 0:\n",
    "        return [lemma]\n",
    "    return [wn_id_from_synset(syn) for syn in synsets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "gold_file = \"../resources/WSD_Evaluation_Framework/Training_Corpora/SemCor/semcor.gold.key.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "XMLEntry = namedtuple(\"Training\", \"id_ lemma pos instance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Training_xml = parse.TrainingParser('../resources/WSD_Evaluation_Framework/Training_Corpora/SemCor/semcor.data.xml')\n",
    "Gold = parse.GoldParser(gold_file)\n",
    "\n",
    "sentence_input = []\n",
    "labels_input = []\n",
    "candidate_synsets = []\n",
    "c=0\n",
    "\n",
    "for sentence in Training_xml.parse():\n",
    "    c += 1\n",
    "    for xmlentry in sentence:\n",
    "        \n",
    "        id_ = xmlentry.id_\n",
    "        lemma = xmlentry.lemma\n",
    "        pos = xmlentry.pos\n",
    "        \n",
    "        sent_word = replacement_routine(l=lemma, entry=xmlentry)\n",
    "        sentence_input.append(sent_word)\n",
    "        \n",
    "        if id_ is None:\n",
    "            labels_input.append(sent_word)\n",
    "            # no instance word, just give the lemma itself as prediction\n",
    "            candidates = [sent_word]\n",
    "        else:\n",
    "            labels = next(Gold.parse())\n",
    "            if labels is not None:\n",
    "                assert labels.id_ == id_, \"ID mismatch\"\n",
    "                sense = labels.senses[0]\n",
    "                #sense = utils.sensekeyToSynsetConverter\n",
    "                sense = output_vocab[sense] if sense in output_vocab else output_vocab[\"<UNK>\"]\n",
    "                labels_input.append(sense)\n",
    "            candidates = u_candidate_synsets(lemma, pos)\n",
    "            #print(candidates)\n",
    "            candidates = [replacement_routine(c, XMLEntry(id_=None, lemma=c, pos=\"X\", instance=True)) for c in candidates]\n",
    "        candidate_synsets.append(candidates)\n",
    "            \n",
    "    if c==1:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 26005, 4, 0, 25921, 4, 0, 27449, 0, 26821, 0, 0, 26822, 0, 26208, 26041, 0]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
