{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm, tnrange\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "from collections import namedtuple\n",
    "\n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow.keras as K\n",
    "\n",
    "import utils\n",
    "import parsers\n",
    "import models\n",
    "\n",
    "training_file_path = '../resources/WSD_Evaluation_Framework/Training_Corpora/SemCor/semcor.data.xml'\n",
    "gold_file_path =  '../resources/WSD_Evaluation_Framework/Training_Corpora/SemCor/semcor.gold.key.txt'\n",
    "\n",
    "# training_file_path = '../resources/WSD_Evaluation_Framework/Evaluation_Datasets/semeval2007/semeval2007.data.xml'\n",
    "# gold_file_path = '../resources/WSD_Evaluation_Framework/Evaluation_Datasets/semeval2007/semeval2007.gold.key.txt'\n",
    "\n",
    "training_file_path_dev = '../resources/WSD_Evaluation_Framework/Evaluation_Datasets/semeval2013/semeval2013.data.xml'\n",
    "gold_file_path_dev = '../resources/WSD_Evaluation_Framework/Evaluation_Datasets/semeval2013/semeval2013.gold.key.txt'\n",
    "fine_senses_vocab_path = '../resources/semcor.vocab.WordNet.json'\n",
    "input_vocab_path = '../resources/semcor.input.vocab.json'\n",
    "input_antivocab_path = '../resources/semcor.leftout.vocab.json'\n",
    "embedding_size = 32\n",
    "batch_size = 64\n",
    "LEARNING_RATE = 0.01\n",
    "N_EPOCHS = 10\n",
    "PADDING_SIZE = 50\n",
    "print_model = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading dict\n",
    "senses = utils.json_vocab_reader(fine_senses_vocab_path)\n",
    "inputs, antivocab = utils.json_vocab_reader(input_vocab_path, input_antivocab_path)\n",
    "output_vocab = utils.vocab_merge(senses, inputs)\n",
    "reverse_output_vocab =  dict((v, k) for k, v in output_vocab.items())\n",
    "\n",
    "K.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_ = \"../resources/WSD_Evaluation_Framework/Evaluation_Datasets\"\n",
    "eval_datasets = [i for i in os.listdir(dir_) if i.startswith(\"se\")]\n",
    "eval_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_file_path = '../resources/WSD_Evaluation_Framework/Evaluation_Datasets/semeval2015/semeval2015.data.xml'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################\n",
    "# # Model loading #\n",
    "# #################\n",
    "loaded_model = K.models.load_model('../resources/models/model_2019-09-06_22:48:47_+0200.h5')\n",
    "loaded_model.load_weights('../resources/models/model_weights_2019-09-06_22:48:47_+0200.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_model.compile(loss = 'categorical_crossentropy',\n",
    "#               optimizer = K.optimizers.Adam(lr=0.0015, clipnorm=1., clipvalue=0.5),\n",
    "#               metrics = ['acc', K.metrics.Precision()])\n",
    "\n",
    "# ## PREDICTION\n",
    "# predicted_one_hot = loaded_model.predict([padded(X_test_uni), padded(X_test_bi)])\n",
    "# #de - one hot encode\n",
    "# predicted = np.argmax(predicted_one_hot, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import generatorPrototype\n",
    "import generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_parser(path = training_file_path_dev, batch_size = 64):\n",
    "    \n",
    "    data_flow = parsers.TrainingParser(path)\n",
    "    sentence_batch = []\n",
    "    for batch_count, sentence in enumerate(data_flow.parse(), start = 1):\n",
    "        sentence_batch.append(sentence)\n",
    "\n",
    "        if len(sentence_batch)==(batch_size):#==0:\n",
    "            yield sentence_batch\n",
    "            sentence_batch = []\n",
    "\n",
    "    if len(sentence_batch)>0:\n",
    "        yield sentence_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_predict(batch_ground_truth_sentences, batch_model_predictions, candidate_synsets):\n",
    "    \n",
    "    outputs = []\n",
    "    output = namedtuple(\"output\", \"Sentence_id WordNet\")\n",
    "    \n",
    "    for idx_sentence, sentence in enumerate(batch_model_predictions):\n",
    "\n",
    "        ground_truth_sentence = batch_ground_truth_sentences[idx_sentence]\n",
    "        \n",
    "        #split based on Model padding\n",
    "        #mfs_part = ground_truth_sentence[PADDING_SIZE+1:]\n",
    "        #ground_truth_sentence = ground_truth_sentence[:PADDING_SIZE]\n",
    "        \n",
    "        for idx, entry in enumerate(ground_truth_sentence):\n",
    "            \n",
    "            if entry.instance == True: #only for instances not wf\n",
    "                if idx<PADDING_SIZE: \n",
    "                    #WSD argmax\n",
    "                    word_prob = sentence[idx]\n",
    "                    current_candidate_synsets = candidate_synsets[idx_sentence][idx]\n",
    "                    prob_dist_candidate_synset = word_prob[current_candidate_synsets]\n",
    "                    current_synset = np.argmax(prob_dist_candidate_synset)\n",
    "\n",
    "                    if current_synset>4: #change after deleting start stop\n",
    "                        item = output(Sentence_id = entry.id_, WordNet = reverse_output_vocab[current_synset])\n",
    "                        outputs.append(item)\n",
    "                    else: #fallback\n",
    "                        word = entry.lemma\n",
    "                        item = output(Sentence_id = entry.id_, WordNet = models.MFS.retrieve_item(word))\n",
    "                        outputs.append(item)\n",
    "                else:\n",
    "                    word = entry.lemma\n",
    "                    item = output(Sentence_id = entry.id_, WordNet = models.MFS.retrieve_item(word))\n",
    "                    outputs.append(item)\n",
    "                \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_file_path_dev = '../resources/WSD_Evaluation_Framework/Evaluation_Datasets/semeval2007/semeval2007.data.xml'\n",
    "training_file_path_dev = '../resources/WSD_Evaluation_Framework/Evaluation_Datasets/semeval2013/semeval2013.data.xml'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368\n",
      "360\n",
      "349\n",
      "300\n",
      "267\n"
     ]
    }
   ],
   "source": [
    "eval_generator = generatorPrototype.get(batch_size = batch_size,\n",
    "                                training_file_path = training_file_path_dev,\n",
    "                                antivocab = antivocab,\n",
    "                                output_vocab = output_vocab,\n",
    "                                PADDING_SIZE = PADDING_SIZE)\n",
    "real_words = eval_parser(path = training_file_path_dev, batch_size = 64)\n",
    "\n",
    "for batch_ground_truth_sentences in real_words:\n",
    "\n",
    "    batch_x, candidate_synsets = next(eval_generator)\n",
    "\n",
    "    batch_model_predictions = loaded_model.predict_on_batch(batch_x)\n",
    "    \n",
    "    outputs = basic_predict(batch_ground_truth_sentences, batch_model_predictions, candidate_synsets)\n",
    "    print(len(outputs))\n",
    "    \n",
    "    #write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[output(Sentence_id='d011.s000.t000', WordNet='wn:00056311n'),\n",
       " output(Sentence_id='d011.s000.t001', WordNet='wn:05832745n'),\n",
       " output(Sentence_id='d011.s000.t002', WordNet='wn:14483917n'),\n",
       " output(Sentence_id='d011.s000.t003', WordNet='wn:08366753n'),\n",
       " output(Sentence_id='d011.s001.t000', WordNet='wn:00056311n'),\n",
       " output(Sentence_id='d011.s001.t001', WordNet='wn:05901508n'),\n",
       " output(Sentence_id='d011.s001.t002', WordNet='wn:05850624n'),\n",
       " output(Sentence_id='d011.s001.t003', WordNet='wn:14320394n'),\n",
       " output(Sentence_id='d011.s001.t004', WordNet='wn:08209687n'),\n",
       " output(Sentence_id='d011.s001.t005', WordNet='wn:02604760v'),\n",
       " output(Sentence_id='d011.s001.t006', WordNet='wn:05901508n'),\n",
       " output(Sentence_id='d011.s001.t007', WordNet='wn:02604760v'),\n",
       " output(Sentence_id='d011.s001.t008', WordNet='wn:07554758n'),\n",
       " output(Sentence_id='d011.s001.t009', WordNet='wn:05901508n'),\n",
       " output(Sentence_id='d011.s001.t010', WordNet='wn:13945919n'),\n",
       " output(Sentence_id='d011.s001.t011', WordNet='wn:08168978n'),\n",
       " output(Sentence_id='d011.s001.t012', WordNet='wn:08168978n'),\n",
       " output(Sentence_id='d011.s001.t013', WordNet='wn:05176846n'),\n",
       " output(Sentence_id='d011.s002.t000', WordNet='wn:07519040n'),\n",
       " output(Sentence_id='d011.s002.t001', WordNet='wn:10665698n'),\n",
       " output(Sentence_id='d011.s002.t002', WordNet='wn:08929922n'),\n",
       " output(Sentence_id='d011.s002.t003', WordNet='wn:05624042n'),\n",
       " output(Sentence_id='d011.s002.t004', WordNet='wn:09874518n'),\n",
       " output(Sentence_id='d011.s002.t005', WordNet='wn:10763383n'),\n",
       " output(Sentence_id='d011.s003.t000', WordNet='wn:06210363n'),\n",
       " output(Sentence_id='d011.s004.t000', WordNet='wn:02604760v'),\n",
       " output(Sentence_id='d011.s004.t001', WordNet='wn:13971901n'),\n",
       " output(Sentence_id='d011.s004.t002', WordNet='wn:08625462n'),\n",
       " output(Sentence_id='d011.s004.t003', WordNet='wn:00696189v'),\n",
       " output(Sentence_id='d011.s004.t004', WordNet='wn:00696189v'),\n",
       " output(Sentence_id='d011.s005.t000', WordNet='wn:00696189v'),\n",
       " output(Sentence_id='d011.s005.t001', WordNet='wn:00696189v'),\n",
       " output(Sentence_id='d011.s005.t002', WordNet='wn:08477307n'),\n",
       " output(Sentence_id='d011.s005.t003', WordNet='wn:14410605n'),\n",
       " output(Sentence_id='d011.s005.t004', WordNet='wn:08168978n'),\n",
       " output(Sentence_id='d011.s005.t005', WordNet='wn:09632518n'),\n",
       " output(Sentence_id='d011.s005.t006', WordNet='wn:08625462n'),\n",
       " output(Sentence_id='d011.s005.t007', WordNet='wn:08929922n'),\n",
       " output(Sentence_id='d011.s005.t008', WordNet='wn:09466280n'),\n",
       " output(Sentence_id='d011.s005.t009', WordNet='wn:14448333n'),\n",
       " output(Sentence_id='d011.s006.t000', WordNet='wn:04748836n'),\n",
       " output(Sentence_id='d011.s006.t001', WordNet='wn:02604760v'),\n",
       " output(Sentence_id='d011.s006.t002', WordNet='wn:04831727n'),\n",
       " output(Sentence_id='d011.s007.t000', WordNet='wn:07519253n'),\n",
       " output(Sentence_id='d011.s007.t001', WordNet='wn:00976531n'),\n",
       " output(Sentence_id='d011.s007.t002', WordNet='wn:08552138n'),\n",
       " output(Sentence_id='d011.s007.t003', WordNet='wn:08182962n'),\n",
       " output(Sentence_id='d011.s007.t004', WordNet='wn:10443032n'),\n",
       " output(Sentence_id='d011.s007.t005', WordNet='wn:08625462n'),\n",
       " output(Sentence_id='d011.s007.t006', WordNet='wn:00696189v'),\n",
       " output(Sentence_id='d011.s008.t000', WordNet='wn:13296899n'),\n",
       " output(Sentence_id='d011.s008.t001', WordNet='wn:10199489n'),\n",
       " output(Sentence_id='d011.s008.t002', WordNet='wn:05832745n'),\n",
       " output(Sentence_id='d011.s008.t003', WordNet='wn:08366753n'),\n",
       " output(Sentence_id='d011.s008.t004', WordNet='wn:07966140n'),\n",
       " output(Sentence_id='d011.s009.t000', WordNet='wn:04748836n'),\n",
       " output(Sentence_id='d011.s009.t001', WordNet='wn:02604760v'),\n",
       " output(Sentence_id='d011.s009.t002', WordNet='wn:04831727n'),\n",
       " output(Sentence_id='d011.s009.t003', WordNet='wn:10199489n'),\n",
       " output(Sentence_id='d011.s010.t000', WordNet='wn:05898568n'),\n",
       " output(Sentence_id='d011.s010.t001', WordNet='wn:07154046n'),\n",
       " output(Sentence_id='d011.s010.t002', WordNet='wn:00056311n'),\n",
       " output(Sentence_id='d011.s010.t003', WordNet='wn:14410605n'),\n",
       " output(Sentence_id='d011.s011.t000', WordNet='wn:05916739n'),\n",
       " output(Sentence_id='d011.s011.t001', WordNet='wn:00056311n'),\n",
       " output(Sentence_id='d011.s011.t002', WordNet='wn:05832745n'),\n",
       " output(Sentence_id='d011.s011.t003', WordNet='wn:14410605n'),\n",
       " output(Sentence_id='d011.s011.t004', WordNet='wn:05154517n'),\n",
       " output(Sentence_id='d011.s012.t000', WordNet='wn:10043643n'),\n",
       " output(Sentence_id='d011.s012.t001', WordNet='wn:01437963a'),\n",
       " output(Sentence_id='d011.s012.t002', WordNet='wn:00023271n'),\n",
       " output(Sentence_id='d011.s012.t003', WordNet='wn:00056311n'),\n",
       " output(Sentence_id='d011.s012.t004', WordNet='wn:07942152n'),\n",
       " output(Sentence_id='d011.s012.t005', WordNet='wn:01123095n'),\n",
       " output(Sentence_id='d011.s012.t006', WordNet='wn:00696189v'),\n",
       " output(Sentence_id='d011.s012.t007', WordNet='wn:15121625n'),\n",
       " output(Sentence_id='d011.s012.t008', WordNet='wn:13971901n'),\n",
       " output(Sentence_id='d011.s012.t009', WordNet='wn:10631941n'),\n",
       " output(Sentence_id='d011.s012.t010', WordNet='wn:07338552n'),\n",
       " output(Sentence_id='d011.s012.t011', WordNet='wn:01123095n'),\n",
       " output(Sentence_id='d011.s012.t012', WordNet='wn:07405893n'),\n",
       " output(Sentence_id='d011.s012.t013', WordNet='wn:13471052n'),\n",
       " output(Sentence_id='d011.s012.t014', WordNet='wn:13279262n'),\n",
       " output(Sentence_id='d011.s012.t015', WordNet='wn:13968092n'),\n",
       " output(Sentence_id='d011.s012.t016', WordNet='wn:08168978n'),\n",
       " output(Sentence_id='d011.s012.t017', WordNet='wn:10199489n'),\n",
       " output(Sentence_id='d011.s013.t000', WordNet='wn:00056311n'),\n",
       " output(Sentence_id='d011.s013.t001', WordNet='wn:01437963a'),\n",
       " output(Sentence_id='d011.s013.t002', WordNet='wn:13968092n'),\n",
       " output(Sentence_id='d011.s014.t000', WordNet='wn:07519253n'),\n",
       " output(Sentence_id='d011.s014.t001', WordNet='wn:07338552n'),\n",
       " output(Sentence_id='d011.s014.t002', WordNet='wn:10199489n'),\n",
       " output(Sentence_id='d011.s014.t003', WordNet='wn:05916739n'),\n",
       " output(Sentence_id='d011.s014.t004', WordNet='wn:09632518n'),\n",
       " output(Sentence_id='d011.s014.t005', WordNet='wn:13742573n'),\n",
       " output(Sentence_id='d011.s014.t006', WordNet='wn:01437963a'),\n",
       " output(Sentence_id='d011.s014.t007', WordNet='wn:13279262n'),\n",
       " output(Sentence_id='d011.s015.t000', WordNet='wn:05758059n'),\n",
       " output(Sentence_id='d011.s015.t001', WordNet='wn:05809878n'),\n",
       " output(Sentence_id='d011.s015.t002', WordNet='wn:10199489n'),\n",
       " output(Sentence_id='d011.s015.t003', WordNet='wn:00197772n'),\n",
       " output(Sentence_id='d011.s015.t004', WordNet='wn:08180639n'),\n",
       " output(Sentence_id='d011.s015.t005', WordNet='wn:01437963a'),\n",
       " output(Sentence_id='d011.s015.t006', WordNet='wn:05114371n'),\n",
       " output(Sentence_id='d011.s015.t007', WordNet='wn:08180639n'),\n",
       " output(Sentence_id='d011.s016.t000', WordNet='wn:10199489n'),\n",
       " output(Sentence_id='d011.s016.t001', WordNet='wn:13875027n'),\n",
       " output(Sentence_id='d011.s016.t002', WordNet='wn:08180639n'),\n",
       " output(Sentence_id='d011.s016.t003', WordNet='wn:13742573n'),\n",
       " output(Sentence_id='d011.s016.t004', WordNet='wn:13875027n'),\n",
       " output(Sentence_id='d011.s016.t005', WordNet='wn:00893955n'),\n",
       " output(Sentence_id='d011.s016.t006', WordNet='wn:07185076n'),\n",
       " output(Sentence_id='d011.s016.t007', WordNet='wn:13968092n'),\n",
       " output(Sentence_id='d011.s017.t000', WordNet='wn:01437963a'),\n",
       " output(Sentence_id='d011.s017.t001', WordNet='wn:13279262n'),\n",
       " output(Sentence_id='d011.s018.t000', WordNet='wn:00584891n'),\n",
       " output(Sentence_id='d011.s018.t001', WordNet='wn:10679174n'),\n",
       " output(Sentence_id='d011.s018.t002', WordNet='wn:08168978n'),\n",
       " output(Sentence_id='d011.s018.t003', WordNet='wn:05114371n'),\n",
       " output(Sentence_id='d011.s018.t004', WordNet='wn:09793495n'),\n",
       " output(Sentence_id='d011.s018.t005', WordNet='wn:13857314n'),\n",
       " output(Sentence_id='d011.s018.t006', WordNet='wn:10199489n'),\n",
       " output(Sentence_id='d011.s018.t007', WordNet='wn:00048225n'),\n",
       " output(Sentence_id='d011.s018.t008', WordNet='wn:10199489n'),\n",
       " output(Sentence_id='d011.s018.t009', WordNet='wn:01437963a'),\n",
       " output(Sentence_id='d011.s018.t010', WordNet='wn:13279262n'),\n",
       " output(Sentence_id='d011.s019.t000', WordNet='wn:02604760v'),\n",
       " output(Sentence_id='d011.s019.t001', WordNet='wn:02604760v'),\n",
       " output(Sentence_id='d011.s019.t002', WordNet='wn:13754293n'),\n",
       " output(Sentence_id='d011.s019.t003', WordNet='wn:13279262n'),\n",
       " output(Sentence_id='d011.s020.t000', WordNet='wn:05817396n'),\n",
       " output(Sentence_id='d011.s020.t001', WordNet='wn:04751305n'),\n",
       " output(Sentence_id='d011.s020.t002', WordNet='wn:10199489n'),\n",
       " output(Sentence_id='d011.s020.t003', WordNet='wn:00908492n'),\n",
       " output(Sentence_id='d011.s020.t004', WordNet='wn:05833840n'),\n",
       " output(Sentence_id='d011.s020.t005', WordNet='wn:13471052n'),\n",
       " output(Sentence_id='d011.s020.t006', WordNet='wn:13815742n'),\n",
       " output(Sentence_id='d011.s020.t007', WordNet='wn:10199489n'),\n",
       " output(Sentence_id='d011.s020.t008', WordNet='wn:09738708n'),\n",
       " output(Sentence_id='d011.s020.t009', WordNet='wn:07268759n'),\n",
       " output(Sentence_id='d011.s020.t010', WordNet='wn:10782940n'),\n",
       " output(Sentence_id='d011.s020.t011', WordNet='wn:06578905n'),\n",
       " output(Sentence_id='d011.s020.t012', WordNet='wn:10804102n'),\n",
       " output(Sentence_id='d011.s020.t013', WordNet='wn:10199489n'),\n",
       " output(Sentence_id='d011.s021.t000', WordNet='wn:10314952n'),\n",
       " output(Sentence_id='d011.s021.t001', WordNet='wn:10670310n'),\n",
       " output(Sentence_id='d011.s021.t002', WordNet='wn:08378819n'),\n",
       " output(Sentence_id='d011.s021.t003', WordNet='wn:13421832n'),\n",
       " output(Sentence_id='d011.s021.t004', WordNet='wn:08696931n'),\n",
       " output(Sentence_id='d011.s022.t000', WordNet='wn:00696189v'),\n",
       " output(Sentence_id='d011.s022.t001', WordNet='wn:08180639n'),\n",
       " output(Sentence_id='d011.s022.t002', WordNet='wn:08164585n'),\n",
       " output(Sentence_id='d011.s022.t003', WordNet='wn:05820620n'),\n",
       " output(Sentence_id='d011.s022.t004', WordNet='wn:08766988n'),\n",
       " output(Sentence_id='d011.s022.t005', WordNet='wn:10199489n'),\n",
       " output(Sentence_id='d011.s022.t006', WordNet='wn:04924103n'),\n",
       " output(Sentence_id='d011.s022.t007', WordNet='wn:00787465n'),\n",
       " output(Sentence_id='d011.s022.t008', WordNet='wn:00090253n'),\n",
       " output(Sentence_id='d011.s022.t009', WordNet='wn:13275288n'),\n",
       " output(Sentence_id='d011.s022.t010', WordNet='wn:06021761n'),\n",
       " output(Sentence_id='d011.s022.t011', WordNet='wn:13661820n'),\n",
       " output(Sentence_id='d011.s022.t012', WordNet='wn:13421832n'),\n",
       " output(Sentence_id='d011.s022.t013', WordNet='wn:15140405n'),\n",
       " output(Sentence_id='d011.s023.t000', WordNet='wn:07325190n'),\n",
       " output(Sentence_id='d011.s023.t001', WordNet='wn:06556481n'),\n",
       " output(Sentence_id='d011.s023.t002', WordNet='wn:02423183v'),\n",
       " output(Sentence_id='d011.s023.t003', WordNet='wn:01437963a'),\n",
       " output(Sentence_id='d011.s024.t000', WordNet='wn:01437963a'),\n",
       " output(Sentence_id='d011.s024.t001', WordNet='wn:10199489n'),\n",
       " output(Sentence_id='d011.s024.t002', WordNet='wn:01437963a'),\n",
       " output(Sentence_id='d012.s000.t000', WordNet='wn:13720096n'),\n",
       " output(Sentence_id='d012.s000.t001', WordNet='wn:13301328n'),\n",
       " output(Sentence_id='d012.s000.t002', WordNet='wn:09044862n'),\n",
       " output(Sentence_id='d012.s001.t000', WordNet='wn:01437963a'),\n",
       " output(Sentence_id='d012.s001.t001', WordNet='wn:13978709n'),\n",
       " output(Sentence_id='d012.s001.t002', WordNet='wn:09916348n'),\n",
       " output(Sentence_id='d012.s001.t003', WordNet='wn:13720096n'),\n",
       " output(Sentence_id='d012.s001.t004', WordNet='wn:13301328n'),\n",
       " output(Sentence_id='d012.s001.t005', WordNet='wn:09044862n'),\n",
       " output(Sentence_id='d012.s002.t000', WordNet='wn:14410605n'),\n",
       " output(Sentence_id='d012.s002.t001', WordNet='wn:02604760v'),\n",
       " output(Sentence_id='d012.s002.t002', WordNet='wn:08065234n'),\n",
       " output(Sentence_id='d012.s002.t003', WordNet='wn:01437963a'),\n",
       " output(Sentence_id='d012.s002.t004', WordNet='wn:15120823n'),\n",
       " output(Sentence_id='d012.s002.t005', WordNet='wn:09044862n'),\n",
       " output(Sentence_id='d012.s002.t006', WordNet='wn:13661273n'),\n",
       " output(Sentence_id='d012.s002.t007', WordNet='wn:13661820n'),\n",
       " output(Sentence_id='d012.s002.t008', WordNet='wn:07181935n'),\n",
       " output(Sentence_id='d012.s002.t009', WordNet='wn:14478684n'),\n",
       " output(Sentence_id='d012.s002.t010', WordNet='wn:08234628n'),\n",
       " output(Sentence_id='d012.s003.t000', WordNet='wn:05814650n'),\n",
       " output(Sentence_id='d012.s003.t001', WordNet='wn:01114824n'),\n",
       " output(Sentence_id='d012.s004.t000', WordNet='wn:04072193n'),\n",
       " output(Sentence_id='d012.s004.t001', WordNet='wn:04337974n'),\n",
       " output(Sentence_id='d012.s004.t002', WordNet='wn:09213565n'),\n",
       " output(Sentence_id='d012.s004.t003', WordNet='wn:07226545n'),\n",
       " output(Sentence_id='d012.s004.t004', WordNet='wn:08234628n'),\n",
       " output(Sentence_id='d012.s005.t000', WordNet='wn:05856388n'),\n",
       " output(Sentence_id='d012.s005.t001', WordNet='wn:14539268n'),\n",
       " output(Sentence_id='d012.s005.t002', WordNet='wn:13933560n'),\n",
       " output(Sentence_id='d012.s005.t003', WordNet='wn:08234628n'),\n",
       " output(Sentence_id='d012.s006.t000', WordNet='wn:05814650n'),\n",
       " output(Sentence_id='d012.s006.t001', WordNet='wn:08256968n'),\n",
       " output(Sentence_id='d012.s006.t002', WordNet='wn:08329453n'),\n",
       " output(Sentence_id='d012.s006.t003', WordNet='wn:10638310n'),\n",
       " output(Sentence_id='d012.s006.t004', WordNet='wn:09119277n'),\n",
       " output(Sentence_id='d012.s007.t000', WordNet='wn:09213565n'),\n",
       " output(Sentence_id='d012.s007.t001', WordNet='wn:13990960n'),\n",
       " output(Sentence_id='d012.s007.t002', WordNet='wn:01437963a'),\n",
       " output(Sentence_id='d012.s008.t000', WordNet='wn:13661273n'),\n",
       " output(Sentence_id='d012.s009.t000', WordNet='wn:10468962n'),\n",
       " output(Sentence_id='d012.s009.t001', WordNet='wn:05653575n'),\n",
       " output(Sentence_id='d012.s009.t002', WordNet='wn:09213565n'),\n",
       " output(Sentence_id='d012.s010.t000', WordNet='wn:09044862n'),\n",
       " output(Sentence_id='d012.s010.t001', WordNet='wn:08234628n'),\n",
       " output(Sentence_id='d012.s010.t002', WordNet='wn:14478684n'),\n",
       " output(Sentence_id='d012.s010.t003', WordNet='wn:09984659n'),\n",
       " output(Sentence_id='d012.s010.t004', WordNet='wn:11445395n'),\n",
       " output(Sentence_id='d012.s011.t000', WordNet='wn:13282550n'),\n",
       " output(Sentence_id='d012.s011.t001', WordNet='wn:00696189v'),\n",
       " output(Sentence_id='d012.s011.t002', WordNet='wn:13752172n'),\n",
       " output(Sentence_id='d012.s012.t000', WordNet='wn:01437963a'),\n",
       " output(Sentence_id='d012.s012.t001', WordNet='wn:05839024n'),\n",
       " output(Sentence_id='d012.s013.t000', WordNet='wn:04072193n'),\n",
       " output(Sentence_id='d012.s013.t001', WordNet='wn:09213565n'),\n",
       " output(Sentence_id='d012.s013.t002', WordNet='wn:15237250n'),\n",
       " output(Sentence_id='d012.s014.t000', WordNet='wn:13340244n'),\n",
       " output(Sentence_id='d012.s016.t000', WordNet='wn:07330007n'),\n",
       " output(Sentence_id='d012.s016.t001', WordNet='wn:02604760v'),\n",
       " output(Sentence_id='d012.s016.t002', WordNet='wn:00696189v'),\n",
       " output(Sentence_id='d012.s016.t003', WordNet='wn:09044862n'),\n",
       " output(Sentence_id='d012.s017.t000', WordNet='wn:09044862n'),\n",
       " output(Sentence_id='d012.s017.t001', WordNet='wn:15212739n'),\n",
       " output(Sentence_id='d012.s017.t002', WordNet='wn:05137165n'),\n",
       " output(Sentence_id='d012.s017.t003', WordNet='wn:13933560n'),\n",
       " output(Sentence_id='d012.s018.t000', WordNet='wn:09213565n'),\n",
       " output(Sentence_id='d012.s018.t001', WordNet='wn:11525955n'),\n",
       " output(Sentence_id='d012.s018.t002', WordNet='wn:09044862n'),\n",
       " output(Sentence_id='d012.s018.t003', WordNet='wn:15203791n'),\n",
       " output(Sentence_id='d012.s019.t000', WordNet='wn:10216106n'),\n",
       " output(Sentence_id='d012.s019.t001', WordNet='wn:04072193n'),\n",
       " output(Sentence_id='d012.s019.t002', WordNet='wn:02604760v'),\n",
       " output(Sentence_id='d012.s019.t003', WordNet='wn:06729864n'),\n",
       " output(Sentence_id='d012.s019.t004', WordNet='wn:13282550n'),\n",
       " output(Sentence_id='d012.s019.t005', WordNet='wn:01134330n'),\n",
       " output(Sentence_id='d012.s020.t000', WordNet='wn:02604760v'),\n",
       " output(Sentence_id='d012.s020.t001', WordNet='wn:06729864n'),\n",
       " output(Sentence_id='d012.s021.t000', WordNet='wn:09213565n'),\n",
       " output(Sentence_id='d012.s021.t001', WordNet='wn:09044862n'),\n",
       " output(Sentence_id='d012.s021.t002', WordNet='wn:10254392n'),\n",
       " output(Sentence_id='d012.s021.t003', WordNet='wn:08384738n'),\n",
       " output(Sentence_id='d012.s021.t004', WordNet='wn:08384539n'),\n",
       " output(Sentence_id='d012.s021.t005', WordNet='wn:13352138n'),\n",
       " output(Sentence_id='d012.s021.t006', WordNet='wn:01106808n'),\n",
       " output(Sentence_id='d012.s021.t007', WordNet='wn:13661273n'),\n",
       " output(Sentence_id='d012.s022.t000', WordNet='wn:01181902n'),\n",
       " output(Sentence_id='d012.s022.t001', WordNet='wn:01106808n'),\n",
       " output(Sentence_id='d012.s022.t002', WordNet='wn:05856388n'),\n",
       " output(Sentence_id='d012.s022.t003', WordNet='wn:13661273n'),\n",
       " output(Sentence_id='d012.s023.t000', WordNet='wn:04072193n'),\n",
       " output(Sentence_id='d012.s023.t001', WordNet='wn:09213565n'),\n",
       " output(Sentence_id='d012.s023.t002', WordNet='wn:01129920n'),\n",
       " output(Sentence_id='d012.s023.t003', WordNet='wn:00696189v'),\n",
       " output(Sentence_id='d012.s023.t004', WordNet='wn:01437963a'),\n",
       " output(Sentence_id='d012.s024.t000', WordNet='wn:06729864n'),\n",
       " output(Sentence_id='d012.s024.t001', WordNet='wn:05982152n'),\n",
       " output(Sentence_id='d012.s024.t002', WordNet='wn:06729864n')]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_predict(batch_ground_truth_sentences, batch_model_predictions, candidate_synsets):\n",
    "    \n",
    "    outputs = []\n",
    "    output = namedtuple(\"output\", \"Sentence_id WordNet\")\n",
    "    \n",
    "    for idx_sentence, sentence in enumerate(batch_model_predictions):\n",
    "        ground_truth_sentence = batch_ground_truth_sentences[idx_sentence]\n",
    "        #print(len(ground_truth_sentence))\n",
    "        #split based on Model padding\n",
    "        mfs_part = ground_truth_sentence[PADDING_SIZE:]\n",
    "        ground_truth_sentence = ground_truth_sentence[:PADDING_SIZE]\n",
    "        #print(len(ground_truth_sentence))\n",
    "        #print(len(ground_truth_sentence))\n",
    "        #print(\"------------_\")\n",
    "        \n",
    "        for idx, entry in enumerate(ground_truth_sentence):\n",
    "           # print(idx_sentence, idx)\n",
    "            if entry.instance == True: #only for instances not wf\n",
    "                if idx<PADDING_SIZE: \n",
    "                    #WSD argmax\n",
    "                    print(idx_sentence, idx)\n",
    "                    word_prob = sentence[idx]\n",
    "                    current_candidate_synsets = candidate_synsets[idx_sentence][idx]\n",
    "                    prob_dist_candidate_synset = word_prob[current_candidate_synsets]\n",
    "                    current_synset = np.argmax(prob_dist_candidate_synset)\n",
    "\n",
    "                    if current_synset>4: #change after deleting start stop\n",
    "                        item = output(Sentence_id = entry.id_, WordNet = reverse_output_vocab[current_synset])\n",
    "                        outputs.append(item)\n",
    "                    else: #fallback\n",
    "                        word = entry.lemma\n",
    "                        item = output(Sentence_id = entry.id_, WordNet = models.MFS.retrieve_item(word))\n",
    "                        outputs.append(item)\n",
    "                else:\n",
    "                    print(\"sex on the beach\")\n",
    "                    word = entry.lemma\n",
    "                    item = output(Sentence_id = entry.id_, WordNet = models.MFS.retrieve_item(word))\n",
    "                    outputs.append(item)\n",
    "                    \n",
    "        for idx, entry in enumerate(mfs_part):\n",
    "            word = entry.lemma\n",
    "            item = output(Sentence_id = entry.id_, WordNet = models.MFS.retrieve_item(word))\n",
    "            outputs.append(item)\n",
    "                \n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic_predict(batch_ground_truth_sentences, batch_model_predictions, candidate_synsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch_model_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_words = utils.eval_parser(path = training_file_path_dev, batch_size = batch_size)\n",
    "\n",
    "for batch_x, candidate_synsets in eval_generator:\n",
    "    print(batch_x.shape)\n",
    "#     batch_real_words = next(real_words)\n",
    "#     batch_predictions = loaded_model.predict_on_batch(batch_x)\n",
    "    \n",
    "    #batch_ground_truth_sentences = next(real_words)\n",
    "    #print(len(batch_ground_truth_sentences))\n",
    "   # batch_model_predictions = loaded_model.predict_on_batch(batch_x)\n",
    "    #print(len(batch_ground_truth_sentences))\n",
    "    #outputs = basic_predict(batch_ground_truth_sentences, batch_model_predictions)\n",
    "    #print(len(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(utils.eval_parser(path = training_file_path_dev, batch_size = 64).__next__())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real_words = utils.eval_parser(path = training_file_path_dev, batch_size = 64)\n",
    "# for i in real_words:\n",
    "#     #print(len(i))\n",
    "#     for q in i:\n",
    "#         for word in q:\n",
    "#             if word.id_ is not None:\n",
    "#                 print(word.id_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_generator = generatorPrototype.get(batch_size = batch_size,\n",
    "                                training_file_path = training_file_path_dev,\n",
    "                                antivocab = antivocab,\n",
    "                                output_vocab = output_vocab,\n",
    "                                PADDING_SIZE = PADDING_SIZE)\n",
    "\n",
    "# real_words = utils.eval_parser(path = training_file_path_dev, batch_size = 64)\n",
    "# for batch_real_words in real_words:\n",
    "#     batch_x, candidate_synsets = next(eval_generator)\n",
    "#     #print(batch_x.shape)\n",
    "#     batch_predictions = loaded_model.predict_on_batch(batch_x)\n",
    "#     outputs = basic_predict(batch_ground_truth_sentences, batch_model_predictions)\n",
    "#     print(len(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-1f5cd08ab92a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mreal_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_file_path_dev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_synsets\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#     batch_real_words = next(real_words)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "real_words = utils.eval_parser(path = training_file_path_dev, batch_size = batch_size)\n",
    "\n",
    "for batch_x, candidate_synsets in eval_generator:\n",
    "    print(batch_x.shape)\n",
    "#     batch_real_words = next(real_words)\n",
    "#     batch_predictions = loaded_model.predict_on_batch(batch_x)\n",
    "    \n",
    "    #batch_ground_truth_sentences = next(real_words)\n",
    "    #print(len(batch_ground_truth_sentences))\n",
    "   # batch_model_predictions = loaded_model.predict_on_batch(batch_x)\n",
    "    #print(len(batch_ground_truth_sentences))\n",
    "    #outputs = basic_predict(batch_ground_truth_sentences, batch_model_predictions)\n",
    "    #print(len(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(eval_generator)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_model_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_real_words in real_words:\n",
    "    print(len(batch_real_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d003.s006.t000 wn:08058098n\n",
      "d003.s006.t001 wn:01110274n\n",
      "d003.s006.t002 wn:08569998n\n",
      "d003.s006.t003 wn:15211806n\n",
      "d003.s007.t000 wn:05926676n\n",
      "d003.s007.t001 wn:14966667n\n",
      "d003.s007.t002 wn:01323781n\n",
      "d003.s007.t003 wn:08913434n\n",
      "d003.s007.t004 wn:08069050n\n",
      "d003.s007.t005 wn:09790482n\n",
      "d003.s008.t000 wn:08913434n\n",
      "d003.s008.t001 wn:03221720n\n",
      "d003.s008.t002 wn:15203791n\n",
      "d003.s008.t003 wn:00973077n\n",
      "d003.s008.t004 wn:08355791n\n",
      "d003.s008.t005 wn:08058098n\n",
      "d003.s008.t006 wn:04928903n\n",
      "d003.s008.t007 wn:10044879n\n",
      "d003.s008.t008 wn:06642138n\n",
      "d003.s008.t009 wn:03748162n\n",
      "d003.s009.t000 wn:15242955n\n",
      "d003.s009.t001 wn:07185076n\n",
      "d003.s009.t002 wn:08913434n\n",
      "d003.s010.t000 wn:05670710n\n",
      "d003.s010.t001 wn:14539268n\n",
      "d003.s010.t002 wn:00978413n\n",
      "d003.s010.t003 wn:15164105n\n",
      "d003.s010.t004 wn:13975659n\n",
      "d003.s010.t005 wn:08355791n\n",
      "d003.s010.t006 wn:08199025n\n",
      "d003.s010.t007 wn:08069241n\n",
      "d003.s010.t008 wn:08913434n\n",
      "d003.s010.t009 wn:09466280n\n",
      "d003.s010.t010 wn:04900121n\n",
      "d003.s010.t011 wn:09790482n\n",
      "d003.s011.t000 wn:08355791n\n",
      "d003.s011.t001 wn:08059870n\n",
      "d003.s011.t002 wn:07308889n\n",
      "d003.s011.t003 wn:05161614n\n",
      "d003.s011.t004 wn:01437963a\n",
      "d003.s011.t005 wn:08050678n\n",
      "d003.s011.t006 wn:11452218n\n",
      "d003.s011.t007 wn:08059870n\n",
      "d003.s011.t008 wn:14541852n\n",
      "d003.s011.t009 wn:10657969n\n",
      "d003.s012.t000 wn:08058098n\n",
      "d003.s012.t001 wn:01110274n\n",
      "d003.s012.t002 wn:08113797n\n",
      "d003.s013.t000 wn:08355791n\n",
      "d003.s013.t001 wn:08059870n\n",
      "d003.s013.t002 wn:03815615n\n",
      "d003.s013.t003 wn:06671484n\n",
      "d003.s013.t004 wn:15203791n\n",
      "d003.s014.t000 wn:08058098n\n",
      "d003.s014.t001 wn:06520944n\n",
      "d003.s014.t002 wn:15170504n\n",
      "d003.s015.t000 wn:07168131n\n",
      "d003.s015.t001 wn:06520944n\n",
      "d003.s015.t002 wn:08058098n\n",
      "d003.s015.t003 wn:13286801n\n",
      "d003.s015.t004 wn:06520944n\n",
      "d003.s015.t005 wn:08569998n\n",
      "d003.s016.t000 wn:08723006n\n",
      "d003.s016.t001 wn:09387222n\n",
      "d003.s016.t002 wn:05190804n\n",
      "d003.s016.t003 wn:10638310n\n",
      "d003.s017.t000 wn:08058098n\n",
      "d003.s017.t001 wn:13596756n\n",
      "d003.s017.t002 wn:10533013n\n",
      "d003.s017.t003 wn:04646990n\n",
      "d003.s017.t004 wn:08913434n\n",
      "d003.s018.t000 wn:08058098n\n",
      "d003.s018.t001 wn:07168131n\n",
      "d003.s018.t002 wn:07185076n\n",
      "d003.s018.t003 wn:02795528n\n",
      "d003.s018.t004 wn:13320168n\n",
      "d003.s018.t005 wn:08113797n\n",
      "d003.s018.t006 wn:03287178n\n",
      "d003.s018.t007 wn:05093890n\n",
      "d003.s018.t008 wn:08569998n\n",
      "d004.s000.t000 wn:09213565n\n",
      "d004.s000.t001 wn:08654360n\n",
      "d004.s000.t002 wn:01215902n\n",
      "d004.s001.t000 wn:09044862n\n",
      "d004.s001.t001 wn:09213565n\n",
      "d004.s001.t002 wn:08654360n\n",
      "d004.s001.t003 wn:04181228n\n",
      "d004.s002.t000 wn:15164233n\n",
      "d004.s002.t001 wn:01215902n\n",
      "d004.s002.t002 wn:09213565n\n",
      "d004.s002.t003 wn:00817680n\n",
      "d004.s002.t004 wn:13358549n\n",
      "d004.s002.t005 wn:13331198n\n",
      "d004.s003.t000 wn:07218470n\n",
      "d004.s003.t001 wn:09044862n\n",
      "d004.s003.t002 wn:00696189v\n",
      "d004.s003.t003 wn:08654360n\n",
      "d004.s003.t004 wn:01215902n\n",
      "d004.s004.t000 wn:08053576n\n",
      "d004.s004.t001 wn:05846355n\n",
      "d004.s004.t002 wn:06193727n\n",
      "d004.s004.t003 wn:13384557n\n",
      "d004.s004.t004 wn:05124057n\n",
      "d004.s004.t005 wn:10014939n\n",
      "d004.s004.t006 wn:05829656n\n",
      "d004.s004.t007 wn:00974762n\n",
      "d004.s005.t000 wn:10216106n\n",
      "d004.s005.t001 wn:13398953n\n",
      "d004.s006.t000 wn:13810818n\n",
      "d004.s006.t001 wn:13331198n\n",
      "d004.s006.t002 wn:13369474n\n",
      "d004.s006.t003 wn:01114824n\n",
      "d004.s006.t004 wn:08061042n\n",
      "d004.s006.t005 wn:13583724n\n",
      "d004.s007.t000 wn:09213565n\n",
      "d004.s008.t000 wn:09213565n\n",
      "d004.s008.t001 wn:05137165n\n",
      "d004.s008.t002 wn:13933560n\n",
      "d004.s008.t003 wn:01099436n\n",
      "d004.s008.t004 wn:09213565n\n",
      "d004.s009.t000 wn:13386614n\n",
      "d004.s009.t001 wn:14530403n\n",
      "d004.s009.t002 wn:08654360n\n",
      "d004.s010.t000 wn:15164354n\n",
      "d004.s010.t001 wn:09044862n\n",
      "d004.s010.t002 wn:09213565n\n",
      "d004.s010.t003 wn:13354420n\n",
      "d004.s010.t004 wn:13754293n\n",
      "d004.s010.t005 wn:06766190n\n",
      "d004.s010.t006 wn:13873502n\n",
      "d004.s011.t000 wn:10638310n\n",
      "d004.s012.t000 wn:01215902n\n",
      "d004.s012.t001 wn:15211806n\n",
      "d005.s000.t000 wn:07186828n\n",
      "d005.s001.t000 wn:13744722n\n",
      "d005.s001.t001 wn:03120778n\n",
      "d005.s001.t002 wn:08431437n\n",
      "d005.s002.t000 wn:07218470n\n",
      "d005.s002.t001 wn:06734467n\n",
      "d005.s003.t000 wn:08566028n\n",
      "d005.s003.t001 wn:00954311n\n",
      "d005.s003.t002 wn:06253690n\n",
      "d005.s003.t003 wn:00791078n\n",
      "d005.s003.t004 wn:11879722n\n",
      "d005.s003.t005 wn:09917593n\n",
      "d005.s003.t006 wn:02818832n\n",
      "d005.s003.t007 wn:03544360n\n",
      "d005.s004.t000 wn:15164354n\n",
      "d005.s004.t001 wn:00791078n\n",
      "d005.s004.t002 wn:10307234n\n",
      "d005.s004.t003 wn:08078020n\n",
      "d005.s004.t004 wn:08566028n\n",
      "d005.s004.t005 wn:10225219n\n",
      "d005.s004.t006 wn:01127623n\n",
      "d005.s004.t007 wn:08414119n\n",
      "d005.s005.t000 wn:10249950n\n",
      "d005.s005.t001 wn:08329453n\n",
      "d005.s005.t002 wn:07167954n\n",
      "d005.s005.t003 wn:07186828n\n",
      "d005.s005.t004 wn:06648724n\n",
      "d005.s005.t005 wn:08329453n\n",
      "d005.s005.t006 wn:15203791n\n",
      "d005.s006.t000 wn:06683784n\n",
      "d005.s006.t001 wn:00791078n\n",
      "d005.s006.t002 wn:10521662n\n",
      "d005.s006.t003 wn:00947128n\n",
      "d005.s006.t004 wn:08189211n\n",
      "d005.s006.t005 wn:14524849n\n",
      "d005.s006.t006 wn:05817845n\n",
      "d005.s006.t007 wn:08414119n\n",
      "d005.s006.t008 wn:07480896n\n",
      "d005.s007.t000 wn:06729864n\n",
      "d005.s007.t001 wn:07186828n\n",
      "d005.s007.t002 wn:10225219n\n",
      "d005.s007.t003 wn:07193596n\n",
      "d005.s007.t004 wn:03120778n\n",
      "d005.s007.t005 wn:05846054n\n",
      "d005.s008.t000 wn:00791078n\n",
      "d005.s008.t001 wn:14540765n\n",
      "d005.s008.t002 wn:13936304n\n",
      "d005.s008.t003 wn:03120778n\n",
      "d005.s008.t004 wn:00007846n\n",
      "d005.s008.t005 wn:05174653n\n",
      "d005.s008.t006 wn:10000158n\n",
      "d005.s009.t000 wn:10728523n\n",
      "d005.s009.t001 wn:08654360n\n",
      "d005.s009.t002 wn:08335751n\n",
      "d005.s009.t003 wn:06729864n\n",
      "d005.s009.t004 wn:01191158n\n",
      "d005.s009.t005 wn:15169873n\n",
      "d005.s009.t006 wn:06266417n\n",
      "d005.s009.t007 wn:05823932n\n",
      "d005.s009.t008 wn:08414119n\n",
      "d005.s009.t009 wn:07480896n\n",
      "d005.s010.t000 wn:06649786n\n",
      "d005.s010.t001 wn:05814650n\n",
      "d005.s011.t000 wn:15204983n\n",
      "d005.s011.t001 wn:08330106n\n",
      "d005.s011.t002 wn:13344664n\n",
      "d005.s011.t003 wn:07308889n\n",
      "d005.s011.t004 wn:07193596n\n",
      "d005.s011.t005 wn:00791078n\n",
      "d005.s011.t006 wn:04839154n\n",
      "d005.s012.t000 wn:01191158n\n",
      "d005.s012.t001 wn:08335886n\n",
      "d005.s012.t002 wn:05942888n\n",
      "d005.s012.t003 wn:09130714n\n",
      "d005.s012.t004 wn:10385566n\n",
      "d005.s012.t005 wn:00220522n\n",
      "d005.s012.t006 wn:10780632n\n",
      "d005.s012.t007 wn:00162632n\n",
      "d005.s012.t008 wn:00511555n\n",
      "d005.s012.t009 wn:14524849n\n",
      "d005.s012.t010 wn:00791078n\n",
      "d005.s012.t011 wn:06266417n\n",
      "d005.s013.t000 wn:00766234n\n",
      "d005.s013.t001 wn:05834567n\n",
      "d005.s013.t002 wn:05981230n\n",
      "d005.s013.t003 wn:02423183v\n",
      "d005.s014.t000 wn:10249950n\n",
      "d005.s014.t001 wn:08330106n\n",
      "d005.s014.t002 wn:05942888n\n",
      "d005.s014.t003 wn:13736799n\n",
      "d005.s014.t004 wn:15205532n\n",
      "d005.s014.t005 wn:06648724n\n",
      "d005.s014.t006 wn:05846054n\n",
      "d005.s014.t007 wn:04928903n\n",
      "d005.s014.t008 wn:03120778n\n",
      "d005.s014.t009 wn:07309599n\n",
      "d005.s014.t010 wn:07308889n\n",
      "d005.s015.t000 wn:09178999n\n",
      "d005.s015.t001 wn:05670710n\n",
      "d005.s015.t002 wn:07338552n\n",
      "d005.s015.t003 wn:00791078n\n",
      "d005.s015.t004 wn:10480730n\n",
      "d005.s015.t005 wn:09068444n\n",
      "d005.s015.t006 wn:01163779n\n",
      "d005.s015.t007 wn:07218470n\n",
      "d005.s016.t000 wn:10480730n\n",
      "d005.s016.t001 wn:07186828n\n",
      "d005.s016.t002 wn:10225219n\n",
      "d005.s016.t003 wn:05833840n\n",
      "d005.s016.t004 wn:06252138n\n",
      "d005.s016.t005 wn:03120778n\n",
      "d005.s016.t006 wn:00791078n\n",
      "d005.s017.t000 wn:05814650n\n",
      "d005.s017.t001 wn:10249950n\n",
      "d005.s017.t002 wn:15203791n\n",
      "d005.s017.t003 wn:01163779n\n",
      "d005.s018.t000 wn:10000158n\n",
      "d005.s018.t001 wn:05820620n\n",
      "d005.s018.t002 wn:10225219n\n",
      "d005.s018.t003 wn:10228278n\n",
      "d005.s018.t004 wn:13447361n\n",
      "d005.s018.t005 wn:03925226n\n",
      "d005.s019.t000 wn:10228278n\n",
      "d005.s019.t001 wn:03925226n\n",
      "d005.s019.t002 wn:10752093n\n",
      "d005.s019.t003 wn:09992837n\n",
      "d005.s020.t000 wn:10000158n\n",
      "d005.s020.t001 wn:01163779n\n",
      "d005.s020.t002 wn:10225219n\n",
      "d005.s020.t003 wn:10228278n\n",
      "d005.s020.t004 wn:10484858n\n",
      "d005.s020.t005 wn:11495041n\n",
      "d005.s020.t006 wn:01192150n\n",
      "d005.s020.t007 wn:00162632n\n",
      "d005.s020.t008 wn:08414119n\n",
      "d005.s020.t009 wn:15170504n\n",
      "d005.s021.t000 wn:10228278n\n",
      "d005.s022.t000 wn:06648724n\n",
      "d005.s022.t001 wn:11410625n\n",
      "d005.s022.t002 wn:13344664n\n",
      "d005.s022.t003 wn:00791078n\n",
      "d005.s022.t004 wn:05682950n\n",
      "d005.s023.t000 wn:13932948n\n",
      "d005.s023.t001 wn:01192150n\n",
      "d005.s023.t002 wn:15209413n\n",
      "d005.s023.t003 wn:07308889n\n",
      "d005.s023.t004 wn:06642138n\n",
      "d005.s023.t005 wn:09068444n\n",
      "d005.s023.t006 wn:00181781n\n",
      "d005.s023.t007 wn:07472929n\n",
      "d005.s023.t008 wn:09889691n\n",
      "d005.s023.t009 wn:08161591n\n",
      "d005.s024.t000 wn:06266417n\n",
      "d005.s024.t001 wn:07480068n\n",
      "d005.s024.t002 wn:07308889n\n",
      "d005.s025.t000 wn:14762366n\n",
      "d005.s025.t001 wn:02942699n\n",
      "d005.s025.t002 wn:10521662n\n",
      "d005.s025.t003 wn:03121431n\n",
      "d005.s025.t004 wn:10249950n\n",
      "d005.s025.t005 wn:09069415n\n",
      "d005.s026.t000 wn:05704694n\n",
      "d005.s026.t001 wn:13344664n\n",
      "d005.s027.t000 wn:07196075n\n",
      "d005.s027.t001 wn:10224578n\n",
      "d005.s027.t002 wn:06729864n\n",
      "d005.s027.t003 wn:06642138n\n",
      "d005.s027.t004 wn:07218470n\n",
      "d005.s027.t005 wn:06208751n\n",
      "d005.s027.t006 wn:08329453n\n",
      "d005.s027.t007 wn:05901508n\n",
      "d005.s027.t008 wn:13344664n\n",
      "d005.s027.t009 wn:00791078n\n",
      "d005.s028.t000 wn:10249950n\n",
      "d005.s028.t001 wn:08330106n\n",
      "d005.s028.t002 wn:06648724n\n",
      "d005.s028.t003 wn:07296428n\n",
      "d005.s028.t004 wn:06408779n\n",
      "d005.s028.t005 wn:08329453n\n",
      "d005.s029.t000 wn:10249950n\n",
      "d005.s029.t001 wn:06729864n\n",
      "d005.s030.t000 wn:07167954n\n",
      "d005.s030.t001 wn:08335886n\n",
      "d005.s030.t002 wn:00162632n\n",
      "d005.s030.t003 wn:05942888n\n",
      "d005.s030.t004 wn:00791078n\n",
      "d005.s030.t005 wn:13344664n\n",
      "d005.s030.t006 wn:05846054n\n",
      "d005.s031.t000 wn:02604760v\n",
      "d005.s031.t001 wn:15205532n\n",
      "d006.s000.t000 wn:00523513n\n",
      "d006.s000.t001 wn:00769092n\n",
      "d006.s000.t002 wn:08441203n\n",
      "d006.s001.t000 wn:00171618n\n",
      "d006.s001.t001 wn:06776138n\n",
      "d006.s001.t002 wn:05652593n\n",
      "d006.s001.t003 wn:06687358n\n",
      "d006.s002.t000 wn:00206927n\n",
      "d006.s002.t001 wn:10439851n\n",
      "d006.s002.t002 wn:00455599n\n",
      "d006.s002.t003 wn:14917635n\n",
      "d006.s002.t004 wn:01220984n\n",
      "d006.s003.t000 wn:15234764n\n",
      "d006.s003.t001 wn:08566028n\n",
      "d006.s003.t002 wn:02626604v\n",
      "d006.s003.t003 wn:08208560n\n",
      "d006.s003.t004 wn:10439851n\n",
      "d006.s003.t005 wn:07309599n\n",
      "d006.s003.t006 wn:10514429n\n",
      "d006.s003.t007 wn:02962545n\n",
      "d006.s004.t000 wn:04928903n\n",
      "d006.s004.t001 wn:09623038n\n",
      "d006.s004.t002 wn:00031264n\n",
      "d006.s004.t003 wn:10439851n\n",
      "d006.s004.t004 wn:06687358n\n",
      "d006.s004.t005 wn:00455599n\n",
      "d006.s004.t006 wn:08231184n\n",
      "d006.s004.t007 wn:02962545n\n",
      "d006.s004.t008 wn:15290337n\n",
      "d006.s005.t000 wn:08324514n\n",
      "d006.s005.t001 wn:05996646n\n",
      "d006.s005.t002 wn:00455599n\n",
      "d006.s005.t003 wn:10722575n\n",
      "d006.s005.t004 wn:08208560n\n",
      "d006.s005.t005 wn:13331198n\n",
      "d006.s005.t006 wn:10439851n\n",
      "d008.s015.t000 wn:15204983n\n",
      "d008.s015.t001 wn:14448910n\n",
      "d008.s015.t002 wn:02626604v\n",
      "d008.s015.t003 wn:01215902n\n",
      "d008.s015.t004 wn:06217103n\n",
      "d008.s016.t000 wn:09466280n\n",
      "d008.s016.t001 wn:08168978n\n",
      "d008.s016.t002 wn:14013368n\n",
      "d008.s016.t003 wn:07419792n\n",
      "d008.s017.t000 wn:02679415n\n",
      "d008.s017.t001 wn:06686467n\n",
      "d008.s018.t000 wn:08295580n\n",
      "d008.s018.t001 wn:08298521n\n",
      "d008.s018.t002 wn:15169873n\n",
      "d008.s018.t003 wn:13815742n\n",
      "d008.s018.t004 wn:14493145n\n",
      "d008.s018.t005 wn:15203791n\n",
      "d008.s019.t000 wn:07551052n\n",
      "d008.s019.t001 wn:08168978n\n",
      "d008.s019.t002 wn:08168978n\n",
      "d008.s019.t003 wn:06999802n\n",
      "d008.s020.t000 wn:08853741n\n",
      "d008.s020.t001 wn:06891493n\n",
      "d008.s020.t002 wn:04808639n\n",
      "d008.s020.t003 wn:10468559n\n",
      "d008.s020.t004 wn:05677504n\n",
      "d008.s020.t005 wn:00249501n\n",
      "d008.s021.t000 wn:08740875n\n",
      "d008.s021.t001 wn:08735705n\n",
      "d008.s021.t002 wn:14013368n\n",
      "d008.s021.t003 wn:00766234n\n",
      "d008.s022.t000 wn:07309599n\n",
      "d008.s022.t001 wn:05800998n\n",
      "d008.s022.t002 wn:10524711n\n",
      "d008.s022.t003 wn:01437963a\n",
      "d008.s022.t004 wn:05869584n\n",
      "d008.s022.t005 wn:00766234n\n",
      "d008.s022.t006 wn:13968308n\n",
      "d008.s022.t007 wn:14410605n\n",
      "d008.s022.t008 wn:08168978n\n",
      "d008.s022.t009 wn:06999802n\n",
      "d008.s023.t000 wn:10235549n\n",
      "d008.s023.t001 wn:10752093n\n",
      "d008.s023.t002 wn:00766234n\n",
      "d008.s023.t003 wn:15203791n\n",
      "d008.s023.t004 wn:15203791n\n",
      "d008.s023.t005 wn:06999647n\n",
      "d008.s024.t000 wn:06891493n\n",
      "d008.s024.t001 wn:01215902n\n",
      "d008.s024.t002 wn:08364959n\n",
      "d008.s024.t003 wn:08364959n\n",
      "d008.s024.t004 wn:10524711n\n",
      "d008.s024.t005 wn:08630039n\n",
      "d008.s024.t006 wn:08364959n\n",
      "d008.s024.t007 wn:00250259n\n",
      "d008.s024.t008 wn:06999802n\n",
      "d008.s025.t000 wn:08364959n\n",
      "d008.s025.t001 wn:04377057n\n",
      "d008.s025.t002 wn:08168978n\n",
      "d008.s025.t003 wn:15203791n\n",
      "d008.s026.t000 wn:10524711n\n",
      "d008.s026.t001 wn:09161803n\n",
      "d008.s026.t002 wn:06208751n\n",
      "d008.s026.t003 wn:08364959n\n",
      "d008.s026.t004 wn:10468559n\n",
      "d008.s026.t005 wn:08058098n\n",
      "d008.s027.t000 wn:00696189v\n",
      "d008.s027.t001 wn:08168978n\n",
      "d008.s027.t002 wn:01256417n\n",
      "d008.s027.t003 wn:08630039n\n",
      "d008.s027.t004 wn:10524711n\n",
      "d008.s027.t005 wn:15203791n\n",
      "d008.s027.t006 wn:02626604v\n",
      "d008.s027.t007 wn:15203791n\n",
      "d008.s027.t008 wn:09161803n\n",
      "d008.s028.t000 wn:09044862n\n",
      "d008.s028.t001 wn:08168978n\n",
      "d008.s028.t002 wn:10524711n\n",
      "d008.s028.t003 wn:08740875n\n",
      "d008.s028.t004 wn:08735705n\n",
      "d008.s028.t005 wn:09161803n\n",
      "d008.s028.t006 wn:05748285n\n",
      "d008.s028.t007 wn:08776687n\n",
      "d008.s028.t008 wn:08752021n\n",
      "d008.s028.t009 wn:08738820n\n",
      "d009.s000.t000 wn:01059900n\n",
      "d009.s000.t001 wn:08441203n\n",
      "d009.s000.t002 wn:10533013n\n",
      "d009.s000.t003 wn:08329453n\n",
      "d009.s000.t004 wn:07308889n\n",
      "d009.s001.t000 wn:15155220n\n",
      "d009.s001.t001 wn:08335886n\n",
      "d009.s001.t002 wn:07193596n\n",
      "d009.s001.t003 wn:13932948n\n",
      "d009.s001.t004 wn:01059900n\n",
      "d009.s001.t005 wn:08441203n\n",
      "d009.s001.t006 wn:04850117n\n",
      "d009.s001.t007 wn:07575726n\n",
      "d009.s001.t008 wn:08064039n\n",
      "d009.s002.t000 wn:07416714n\n",
      "d009.s002.t001 wn:15164354n\n",
      "d009.s002.t002 wn:04850117n\n",
      "d009.s002.t003 wn:08308497n\n",
      "d009.s002.t004 wn:13296899n\n",
      "d009.s002.t005 wn:05747582n\n",
      "d009.s003.t000 wn:07308889n\n",
      "d009.s003.t001 wn:05814650n\n",
      "d009.s003.t002 wn:04350905n\n",
      "d009.s003.t003 wn:08654360n\n",
      "d009.s003.t004 wn:01059900n\n",
      "d009.s003.t005 wn:00268112n\n",
      "d009.s003.t006 wn:08161757n\n",
      "d009.s003.t007 wn:15203791n\n",
      "d009.s003.t008 wn:08441203n\n",
      "d009.s003.t009 wn:07152752n\n",
      "d009.s003.t010 wn:10315837n\n",
      "d009.s004.t000 wn:04850117n\n",
      "d009.s004.t001 wn:04350905n\n",
      "d009.s004.t002 wn:15227846n\n",
      "d009.s004.t003 wn:06648724n\n",
      "d009.s004.t004 wn:15210870n\n",
      "d009.s004.t005 wn:07292694n\n",
      "d009.s004.t006 wn:07472657n\n",
      "d009.s004.t007 wn:14009946n\n",
      "d009.s004.t008 wn:07309599n\n",
      "d009.s004.t009 wn:08329453n\n",
      "d009.s004.t010 wn:00162632n\n",
      "d009.s005.t000 wn:10249950n\n",
      "d009.s005.t001 wn:08329453n\n",
      "d009.s005.t002 wn:08441203n\n",
      "d009.s006.t000 wn:08064039n\n",
      "d009.s006.t001 wn:13748622n\n",
      "d009.s006.t002 wn:08059870n\n",
      "d009.s006.t003 wn:07575726n\n",
      "d009.s006.t004 wn:05956651n\n",
      "d009.s007.t000 wn:08059870n\n",
      "d009.s007.t001 wn:07575726n\n",
      "d009.s007.t002 wn:08441203n\n",
      "d009.s008.t000 wn:10407954n\n",
      "d009.s008.t001 wn:01323781n\n",
      "d009.s008.t002 wn:13286801n\n",
      "d009.s008.t003 wn:07292694n\n",
      "d009.s008.t004 wn:01186810n\n",
      "d009.s009.t000 wn:07575726n\n",
      "d009.s009.t001 wn:09070793n\n",
      "d009.s009.t002 wn:03542333n\n",
      "d009.s009.t003 wn:15227846n\n",
      "d009.s009.t004 wn:08329453n\n",
      "d009.s009.t005 wn:08308497n\n",
      "d009.s009.t006 wn:07308889n\n",
      "d009.s010.t000 wn:01233397n\n",
      "d009.s010.t001 wn:08161477n\n",
      "d009.s010.t002 wn:10379620n\n",
      "d009.s011.t000 wn:10150940n\n",
      "d009.s011.t001 wn:07575726n\n",
      "d009.s012.t000 wn:04850117n\n",
      "d009.s012.t001 wn:00029378n\n",
      "d009.s012.t002 wn:15203791n\n",
      "d009.s013.t000 wn:13740168n\n",
      "d009.s013.t001 wn:05956019n\n",
      "d009.s013.t002 wn:05846054n\n",
      "d009.s014.t000 wn:05817396n\n",
      "d009.s014.t001 wn:04850117n\n",
      "d009.s014.t002 wn:05668095n\n",
      "d009.s014.t003 wn:00037396n\n",
      "d009.s014.t004 wn:04850117n\n",
      "d009.s015.t000 wn:06667317n\n",
      "d009.s015.t001 wn:06664594n\n",
      "d009.s015.t002 wn:10225219n\n",
      "d009.s015.t003 wn:00029378n\n",
      "d009.s015.t004 wn:08008335n\n",
      "d009.s015.t005 wn:05981230n\n",
      "d009.s015.t006 wn:10630188n\n",
      "d009.s015.t007 wn:10151261n\n",
      "d009.s015.t008 wn:05898568n\n",
      "d009.s015.t009 wn:00029378n\n",
      "d009.s016.t000 wn:05085867n\n",
      "d009.s016.t001 wn:08064039n\n",
      "d009.s016.t002 wn:07308889n\n",
      "d009.s016.t003 wn:08058098n\n",
      "d009.s016.t004 wn:05682950n\n",
      "d009.s016.t005 wn:10315837n\n",
      "d009.s017.t000 wn:00068901n\n",
      "d009.s017.t001 wn:05956019n\n",
      "d009.s017.t002 wn:07505676n\n",
      "d009.s017.t003 wn:06667317n\n",
      "d009.s017.t004 wn:06729864n\n",
      "d009.s017.t005 wn:04850117n\n",
      "d009.s017.t006 wn:08329453n\n",
      "d009.s017.t007 wn:05846054n\n",
      "d009.s017.t008 wn:10468559n\n",
      "d009.s018.t000 wn:04850117n\n",
      "d009.s018.t001 wn:10116478n\n",
      "d009.s018.t002 wn:10249950n\n",
      "d009.s018.t003 wn:07308889n\n",
      "d009.s018.t004 wn:08329453n\n",
      "d009.s019.t000 wn:04673965n\n",
      "d009.s019.t001 wn:01207609n\n",
      "d009.s019.t002 wn:00029378n\n",
      "d009.s019.t003 wn:06729864n\n",
      "d009.s019.t004 wn:06202686n\n",
      "d009.s020.t000 wn:05820170n\n",
      "d009.s020.t001 wn:09979589n\n",
      "d009.s020.t002 wn:08061042n\n",
      "d009.s020.t003 wn:08329453n\n",
      "d009.s020.t004 wn:00031264n\n",
      "d009.s021.t000 wn:10780632n\n",
      "d009.s021.t001 wn:10315837n\n",
      "d009.s022.t000 wn:09957156n\n",
      "d009.s022.t001 wn:04850117n\n",
      "d009.s022.t002 wn:05814650n\n",
      "d009.s023.t000 wn:10623533n\n",
      "d009.s023.t001 wn:01135952n\n",
      "d009.s023.t002 wn:13932948n\n",
      "d009.s023.t003 wn:08441203n\n",
      "d009.s023.t004 wn:08336490n\n",
      "d009.s023.t005 wn:05093890n\n",
      "d009.s024.t000 wn:09979589n\n",
      "d009.s024.t001 wn:07308889n\n",
      "d009.s024.t002 wn:08441203n\n",
      "d009.s025.t000 wn:06797169n\n",
      "d010.s000.t000 wn:05817145n\n",
      "d010.s001.t000 wn:10439851n\n",
      "d010.s001.t001 wn:09023321n\n",
      "d010.s001.t002 wn:00455599n\n",
      "d010.s002.t000 wn:08649345n\n",
      "d010.s002.t001 wn:08736107n\n",
      "d010.s002.t002 wn:10439851n\n",
      "d010.s002.t003 wn:00455599n\n",
      "d010.s003.t000 wn:13855627n\n",
      "d010.s003.t001 wn:08736107n\n",
      "d010.s003.t002 wn:10439851n\n",
      "d010.s003.t003 wn:08168978n\n",
      "d010.s003.t004 wn:00455599n\n",
      "d010.s003.t005 wn:15262921n\n",
      "d010.s003.t006 wn:09066017n\n",
      "d010.s004.t000 wn:09275473n\n",
      "d010.s004.t001 wn:09605110n\n",
      "d010.s004.t002 wn:08663860n\n",
      "d010.s004.t003 wn:06647206n\n",
      "d010.s004.t004 wn:00161243n\n",
      "d010.s004.t005 wn:00455599n\n",
      "d010.s005.t000 wn:05121418n\n",
      "d010.s005.t001 wn:15164463n\n",
      "d010.s005.t002 wn:00455599n\n",
      "d010.s005.t003 wn:08739206n\n",
      "d010.s006.t000 wn:10101634n\n",
      "d010.s006.t001 wn:08231184n\n",
      "d010.s006.t002 wn:08079613n\n",
      "d010.s006.t003 wn:08871007n\n",
      "d010.s006.t004 wn:15203791n\n",
      "d010.s006.t005 wn:08231184n\n",
      "d010.s006.t006 wn:03147509n\n",
      "d010.s006.t007 wn:13837009n\n",
      "d010.s006.t008 wn:07510625n\n",
      "d010.s007.t000 wn:05758059n\n",
      "d010.s007.t001 wn:07464568n\n",
      "d010.s008.t000 wn:10439851n\n",
      "d010.s008.t001 wn:05758059n\n",
      "d010.s008.t002 wn:08497294n\n",
      "d010.s008.t003 wn:05093890n\n",
      "d010.s009.t000 wn:13653902n\n",
      "d010.s009.t001 wn:00161243n\n",
      "d010.s009.t002 wn:10134001n\n",
      "d010.s009.t003 wn:15164570n\n",
      "d010.s009.t004 wn:08871007n\n",
      "d010.s009.t005 wn:00455599n\n",
      "d010.s009.t006 wn:08873622n\n",
      "d010.s009.t007 wn:06647206n\n",
      "d010.s009.t008 wn:10134001n\n",
      "d010.s009.t009 wn:03728437n\n",
      "d010.s010.t000 wn:15262921n\n",
      "d010.s010.t001 wn:06647206n\n",
      "d010.s010.t002 wn:03728437n\n",
      "d010.s011.t000 wn:10439851n\n",
      "d010.s011.t001 wn:03728437n\n",
      "d010.s012.t000 wn:15169873n\n",
      "d010.s012.t001 wn:10439851n\n",
      "d010.s012.t002 wn:08208560n\n",
      "d010.s012.t003 wn:03728437n\n",
      "d010.s012.t004 wn:10663996n\n",
      "d010.s013.t000 wn:05121418n\n",
      "d010.s013.t001 wn:00455599n\n",
      "d010.s015.t000 wn:08649345n\n",
      "d010.s015.t001 wn:03728437n\n",
      "d010.s015.t002 wn:10663996n\n",
      "d010.s016.t000 wn:00455599n\n",
      "d010.s018.t000 wn:03728437n\n",
      "d010.s018.t001 wn:09023321n\n",
      "d010.s019.t000 wn:08649345n\n",
      "d010.s019.t001 wn:13957601n\n",
      "d010.s020.t000 wn:13810818n\n",
      "d010.s021.t000 wn:00455599n\n",
      "d010.s021.t001 wn:08736107n\n",
      "d010.s022.t000 wn:10562391n\n",
      "d010.s022.t001 wn:05980875n\n",
      "d010.s023.t000 wn:05865998n\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-142-355cff9f2592>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mbatch_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mbatch_ground_truth_sentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mbatch_model_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "eval_generator = generatorPrototype.get(batch_size = batch_size,\n",
    "                                training_file_path = training_file_path_dev,\n",
    "                                antivocab = antivocab,\n",
    "                                output_vocab = output_vocab,\n",
    "                                PADDING_SIZE = PADDING_SIZE)\n",
    "\n",
    "real_words = eval_parser(path = training_file_path_dev, batch_size = batch_size)\n",
    "\n",
    "for batch_x, candidate_synsets in eval_generator:\n",
    "\n",
    "    batch_real_words = next(real_words)\n",
    "    batch_predictions = loaded_model.predict_on_batch(batch_x)\n",
    "    \n",
    "    batch_ground_truth_sentences = next(real_words)\n",
    "    batch_model_predictions = loaded_model.predict_on_batch(batch_x)\n",
    "    \n",
    "    for idx_sentence, sentence in enumerate(batch_predictions):\n",
    "\n",
    "        ground_truth_sentence = batch_ground_truth_sentences[idx_sentence]\n",
    "\n",
    "        #split based on Model padding\n",
    "        ground_truth_sentence = ground_truth_sentence[:PADDING_SIZE]\n",
    "        mfs_part = ground_truth_sentence[PADDING_SIZE+1:]\n",
    "        \n",
    "        for idx, entry in enumerate(ground_truth_sentence):\n",
    "            \n",
    "            #only for instances not wf\n",
    "            if entry.instance == True:\n",
    "                if idx<PADDING_SIZE:\n",
    "                    \n",
    "                    #WSD argmax\n",
    "                    word_prob = sentence[idx]\n",
    "                    current_candidate_synsets = candidate_synsets[idx_sentence][idx]\n",
    "                    prob_dist_candidate_synset = word_prob[current_candidate_synsets]\n",
    "                    current_synset = np.argmax(prob_dist_candidate_synset)\n",
    "\n",
    "                    if current_synset>4: #change after deleting start stop\n",
    "                        single_lemma_prediction = reverse_output_vocab[current_synset]\n",
    "                        print(entry.id_, single_lemma_prediction)\n",
    "                    else:\n",
    "                        word = entry.lemma\n",
    "                        print(entry.id_, models.MFS.retrieve_item(word))\n",
    "                        \n",
    "                else:\n",
    "                    word = entry.lemma\n",
    "                    print(entry.id_, models.MFS.retrieve_item(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(real_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(batch_model_predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MFS(object):\n",
    "    \"\"\"\n",
    "    WSD performed via Most Frequent Sense (MFS) which always returns the predominant sense of a lemma\n",
    "    \"\"\"\n",
    "\n",
    "    def retrieve_item(lemma):\n",
    "        \"\"\"\n",
    "        Retreives the MFS of a lemma from the nltk package if exists else word\n",
    "        \"\"\"\n",
    "        synsets = wn.synsets(str(lemma))\n",
    "        \n",
    "        if len(synsets) == 0:\n",
    "            print(\"fail\")\n",
    "            return lemma\n",
    "        else:\n",
    "            mfs = synsets[0]\n",
    "            return utils.WordNet.from_synset(mfs)\n",
    "\n",
    "    def predict(sentence):\n",
    "        \"\"\"\n",
    "        param: sentence of lemmas\n",
    "        return sentence MFS\n",
    "        \"\"\"\n",
    "        return [MFS.retrieve_item(lemma) for lemma in sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PADDING_SIZE = 50\n",
    "for idx_sentence, sentence in enumerate(predictions):\n",
    "    print(idx_sentence)\n",
    "    real_sentence = batch_real_words[idx_sentence]\n",
    "    \n",
    "    #split based on Model padding\n",
    "    real_sentence, mfs_part = real_sentence[:50], real_sentence[51:]\n",
    "    for idx, entry in enumerate(real_sentence):\n",
    "        \n",
    "        if entry.instance == True:\n",
    "            if idx<PADDING_SIZE:\n",
    "                word_prob = sentence[idx]\n",
    "\n",
    "                current_candidate_synsets = candidate_synsets[idx_sentence][idx]\n",
    "                prob_dist_candidate_synset = word_prob[current_candidate_synsets]\n",
    "                current_synset = np.argmax(prob_dist_candidate_synset)\n",
    "\n",
    "                if current_synset>4:#change after deleting start stop\n",
    "                    single_lemma_prediction = reverse_output_vocab[current_synset]\n",
    "                    print(entry.id_, single_lemma_prediction)\n",
    "                else:\n",
    "                    word = entry.lemma\n",
    "                    print(entry.id_, MFS.retrieve_item(word))\n",
    "            else:\n",
    "                word = entry.lemma\n",
    "                print(entry.id_, MFS.retrieve_item(word))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
