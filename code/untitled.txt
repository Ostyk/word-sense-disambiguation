    def prepare_sentence(self, sentence, antivocab, output_vocab, labels=None):
        """
        Builds data structures for training and querying the BasicTagger model.
        If labels is specified, the model expects to be in training mode; otherwise: querying mode.

        :param sentence: List of XMLEntry objects produced by a TrainParser object
        :param antivocab: List of sub-sampled words
        :param output_vocab: Dictionary str -> int
        :param labels: List of GoldEntry objects produced by a GoldParser object (optional)
        :return: (sentence_input, labels_input, candidate_synsets)
        """

        # check vocabulary alignment with the output layer
        assert len(output_vocab) == self.output_size

        def replacement_routine(l, entry):
            ret_word = None
            if l in antivocab:
                ret_word = output_vocab["<SUB>"]

            if entry.has_instance or ret_word is None:
                if l in output_vocab:
                    ret_word = output_vocab[l]
                elif ret_word is None:
                    ret_word = output_vocab["<UNK>"]

            return ret_word

        sentence_input = []
        labels_input = []
        candidate_synsets = []
        for xmlentry in sentence:
            iid = xmlentry.id
            lemma = xmlentry.lemma
            pos = xmlentry.pos

            sent_word = replacement_routine(l=lemma, entry=xmlentry)
            sentence_input.append(sent_word)
            if iid is None:
                labels_input.append(sent_word)

                # no instance word, just give the lemma itself as prediction
                candidates = [sent_word]
            else:
                iid = iid.split(".")[2][1:]
                iid = int(iid)

                if labels is not None:
                    sense = labels[iid].senses[0]
                    sense = output_vocab[sense] if sense in output_vocab else output_vocab["<UNK>"]
                    labels_input.append(sense)

                # fetch real synsets and get their mapping in the output vocabulary
                candidates = u.candidate_synsets(lemma, pos)
                candidates = [replacement_routine(c, ch.XMLEntry(id=None, lemma=c, pos="X", has_instance=True)) for c in candidates]

            candidate_synsets.append(candidates)

        return sentence_input, labels_input, candidate_synsets