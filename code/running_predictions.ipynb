{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import predict\n",
    "import os\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['semeval2007', 'semeval2015', 'senseval2', 'senseval3']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_ = \"../resources/WSD_Evaluation_Framework/Evaluation_Datasets\"\n",
    "eval_datasets = sorted([i for i in os.listdir(dir_) if i.startswith(\"se\")])\n",
    "resources_path = '../resources'\n",
    "del eval_datasets[1]\n",
    "eval_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(b'', None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bashCommand = \"sudo javac ../resources/WSD_Evaluation_Framework/Evaluation_Datasets/Scorer.java\"\n",
    "process = subprocess.Popen(bashCommand.split(), stdout=subprocess.PIPE)\n",
    "output, error = process.communicate()\n",
    "output,error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'babelnet': {'semeval2007': None,\n",
       "  'semeval2015': None,\n",
       "  'senseval2': None,\n",
       "  'senseval3': None},\n",
       " 'lexicographer': {'semeval2007': None,\n",
       "  'semeval2015': None,\n",
       "  'senseval2': None,\n",
       "  'senseval3': None},\n",
       " 'wordnet_domains': {'semeval2007': None,\n",
       "  'semeval2015': None,\n",
       "  'senseval2': None,\n",
       "  'senseval3': None}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = {\"babelnet\": {}, 'wordnet_domains': {}, 'lexicographer': {}}\n",
    "for name in eval_datasets:\n",
    "    for key in list(scores.keys()):\n",
    "        scores[key].update({name:None})\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = namedtuple(\"predictions\", \"build perform\")\n",
    "\n",
    "Basic_model = record(True, True)\n",
    "\n",
    "MFS_baseline = record(False, False)\n",
    "\n",
    "\n",
    "#assert not (perform_predictions and MFS_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: semeval2007\n",
      "\n",
      "../resources/WSD_Evaluation_Framework/Evaluation_Datasets/semeval2007/semeval2007.data.xml\n",
      "__________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "batch: : 3it [00:05,  1.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done writing to:\t../resources/WSD_Evaluation_Framework/Evaluation_Datasets/semeval2007/semeval2007.pred.babelnet.txt\n",
      "babelnet: semeval2007\n",
      "P=\t34.3%\n",
      "R=\t34.3%\n",
      "F1=\t34.3%\n",
      "\n",
      "__________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "batch: : 3it [00:04,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done writing to:\t../resources/WSD_Evaluation_Framework/Evaluation_Datasets/semeval2007/semeval2007.pred.wordnet_domains.txt\n",
      "wordnet_domains: semeval2007\n",
      "P=\t73.2%\n",
      "R=\t73.2%\n",
      "F1=\t73.2%\n",
      "\n",
      "__________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "batch: : 3it [00:04,  1.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done writing to:\t../resources/WSD_Evaluation_Framework/Evaluation_Datasets/semeval2007/semeval2007.pred.lexicographer.txt\n",
      "lexicographer: semeval2007\n",
      "P=\t40.9%\n",
      "R=\t40.9%\n",
      "F1=\t40.9%\n",
      "\n",
      "__________________________________________________\n",
      "__________________________________________________\n",
      "__________________________________________________\n",
      "Dataset: semeval2015\n",
      "\n",
      "../resources/WSD_Evaluation_Framework/Evaluation_Datasets/semeval2015/semeval2015.data.xml\n",
      "__________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "batch: : 3it [00:08,  2.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done writing to:\t../resources/WSD_Evaluation_Framework/Evaluation_Datasets/semeval2015/semeval2015.pred.babelnet.txt\n",
      "babelnet: semeval2015\n",
      "P=\t41.2%\n",
      "R=\t41.2%\n",
      "F1=\t41.2%\n",
      "\n",
      "__________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "batch: : 3it [00:08,  2.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done writing to:\t../resources/WSD_Evaluation_Framework/Evaluation_Datasets/semeval2015/semeval2015.pred.wordnet_domains.txt\n",
      "wordnet_domains: semeval2015\n",
      "P=\t71.3%\n",
      "R=\t71.3%\n",
      "F1=\t71.3%\n",
      "\n",
      "__________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "batch: : 3it [00:08,  2.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done writing to:\t../resources/WSD_Evaluation_Framework/Evaluation_Datasets/semeval2015/semeval2015.pred.lexicographer.txt\n",
      "lexicographer: semeval2015\n",
      "P=\t52.7%\n",
      "R=\t52.7%\n",
      "F1=\t52.7%\n",
      "\n",
      "__________________________________________________\n",
      "__________________________________________________\n",
      "__________________________________________________\n",
      "Dataset: senseval2\n",
      "\n",
      "../resources/WSD_Evaluation_Framework/Evaluation_Datasets/senseval2/senseval2.data.xml\n",
      "__________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "batch: : 4it [00:17,  4.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done writing to:\t../resources/WSD_Evaluation_Framework/Evaluation_Datasets/senseval2/senseval2.pred.babelnet.txt\n",
      "babelnet: senseval2\n",
      "P=\t46.6%\n",
      "R=\t46.6%\n",
      "F1=\t46.6%\n",
      "\n",
      "__________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "batch: : 4it [00:17,  4.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done writing to:\t../resources/WSD_Evaluation_Framework/Evaluation_Datasets/senseval2/senseval2.pred.wordnet_domains.txt\n",
      "wordnet_domains: senseval2\n",
      "P=\t77.8%\n",
      "R=\t77.8%\n",
      "F1=\t77.8%\n",
      "\n",
      "__________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "batch: : 4it [00:17,  4.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done writing to:\t../resources/WSD_Evaluation_Framework/Evaluation_Datasets/senseval2/senseval2.pred.lexicographer.txt\n",
      "lexicographer: senseval2\n",
      "P=\t56.6%\n",
      "R=\t56.6%\n",
      "F1=\t56.6%\n",
      "\n",
      "__________________________________________________\n",
      "__________________________________________________\n",
      "__________________________________________________\n",
      "Dataset: senseval3\n",
      "\n",
      "../resources/WSD_Evaluation_Framework/Evaluation_Datasets/senseval3/senseval3.data.xml\n",
      "__________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "batch: : 6it [00:16,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done writing to:\t../resources/WSD_Evaluation_Framework/Evaluation_Datasets/senseval3/senseval3.pred.babelnet.txt\n",
      "babelnet: senseval3\n",
      "P=\t43.1%\n",
      "R=\t43.1%\n",
      "F1=\t43.1%\n",
      "\n",
      "__________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "batch: : 6it [00:16,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done writing to:\t../resources/WSD_Evaluation_Framework/Evaluation_Datasets/senseval3/senseval3.pred.wordnet_domains.txt\n",
      "wordnet_domains: senseval3\n",
      "P=\t72.2%\n",
      "R=\t72.2%\n",
      "F1=\t72.2%\n",
      "\n",
      "__________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "batch: : 6it [00:16,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done writing to:\t../resources/WSD_Evaluation_Framework/Evaluation_Datasets/senseval3/senseval3.pred.lexicographer.txt\n",
      "lexicographer: senseval3\n",
      "P=\t51.3%\n",
      "R=\t51.3%\n",
      "F1=\t51.3%\n",
      "\n",
      "__________________________________________________\n",
      "__________________________________________________\n",
      "__________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for name in eval_datasets:\n",
    "    print(\"Dataset: {}\\n\".format(name))\n",
    "    path = os.path.join(dir_, name)\n",
    "    xml_file = [i for i in os.listdir(path) if i.endswith('.xml')][0]\n",
    "    xml_file = os.path.join(path, xml_file)\n",
    "    print(xml_file)\n",
    "    print(\"_\"*50)\n",
    "    if Basic_model.build:\n",
    "        predict.predict_babelnet(input_path =   '../resources/WSD_Evaluation_Framework/Evaluation_Datasets/{}/{}.data.xml'.format(name, name),\n",
    "                                 output_path = '../resources/WSD_Evaluation_Framework/Evaluation_Datasets/{}/{}.pred.babelnet.txt'.format(name, name),\n",
    "                                 resources_path = resources_path)\n",
    "    if Basic_model.perform:\n",
    "        bashCommand = \"sudo java Scorer {}/{}.gold.babelnet.txt {}/{}.pred.babelnet.txt\".format(name, name, name, name)\n",
    "    if MFS_baseline.build:\n",
    "        predict.MFS_predict_writer(input_path =   '../resources/WSD_Evaluation_Framework/Evaluation_Datasets/{}/{}.data.xml'.format(name, name),\n",
    "                                   output_path = '../resources/WSD_Evaluation_Framework/Evaluation_Datasets/{}/MFS.{}.pred.babelnet.txt'.format(name, name),\n",
    "                                   resources_path = resources_path,\n",
    "                                   prediction_type = 'babelnet')\n",
    "    if MFS_baseline.perform:\n",
    "        bashCommand = \"sudo java Scorer {}/{}.gold.babelnet.txt {}/MFS.{}.pred.babelnet.txt\".format(name, name, name, name)\n",
    "    ########################################################\n",
    "    os.chdir(\"../resources/WSD_Evaluation_Framework/Evaluation_Datasets/\")\n",
    "    process = subprocess.Popen(bashCommand.split(), stdout=subprocess.PIPE)\n",
    "    output, error = process.communicate()\n",
    "    scores['babelnet'][name] = float(output.decode(\"UTF-8\").split(\"\\n\")[0].split(\"\\t\")[1].split(\"%\")[0])\n",
    "    print(\"babelnet: {}\".format(name))\n",
    "    for i in output.decode(\"UTF-8\").split(\"\\n\"):\n",
    "        print(i)\n",
    "    os.chdir(\"../../../code\")\n",
    "    \n",
    "    ########################################################\n",
    "    ########################################################\n",
    "    ########################################################\n",
    "    \n",
    "    print(\"_\"*50)\n",
    "    if Basic_model.build:\n",
    "        predict.predict_wordnet_domains(input_path =   '../resources/WSD_Evaluation_Framework/Evaluation_Datasets/{}/{}.data.xml'.format(name, name),\n",
    "                                        output_path = '../resources/WSD_Evaluation_Framework/Evaluation_Datasets/{}/{}.pred.wordnet_domains.txt'.format(name, name),\n",
    "                                        resources_path = resources_path)\n",
    "    if Basic_model.perform:\n",
    "        bashCommand = \"sudo java Scorer {}/{}.gold.wordnet_domains.txt {}/{}.pred.wordnet_domains.txt\".format(name, name, name, name)\n",
    "    \n",
    "    if MFS_baseline.build:\n",
    "        predict.MFS_predict_writer(input_path =   '../resources/WSD_Evaluation_Framework/Evaluation_Datasets/{}/{}.data.xml'.format(name, name),\n",
    "                                   output_path = '../resources/WSD_Evaluation_Framework/Evaluation_Datasets/{}/MFS.{}.pred.wordnet_domains.txt'.format(name, name),\n",
    "                                   resources_path = resources_path,\n",
    "                                   prediction_type = 'wordnet_domains')\n",
    "    if MFS_baseline.perform:\n",
    "        bashCommand = \"sudo java Scorer {}/{}.gold.wordnet_domains.txt {}/MFS.{}.pred.wordnet_domains.txt\".format(name, name, name, name)    \n",
    "        \n",
    "        \n",
    "    ########################################################\n",
    "    os.chdir(\"../resources/WSD_Evaluation_Framework/Evaluation_Datasets/\")\n",
    "    process = subprocess.Popen(bashCommand.split(), stdout=subprocess.PIPE)\n",
    "    output, error = process.communicate()\n",
    "    scores['wordnet_domains'][name] = float(output.decode(\"UTF-8\").split(\"\\n\")[0].split(\"\\t\")[1].split(\"%\")[0])\n",
    "    print(\"wordnet_domains: {}\".format(name))\n",
    "    for i in output.decode(\"UTF-8\").split(\"\\n\"):\n",
    "        print(i)\n",
    "    os.chdir(\"../../../code\")\n",
    "    \n",
    "    ########################################################\n",
    "    ########################################################\n",
    "    ########################################################\n",
    "    print(\"_\"*50)\n",
    "    if Basic_model.build:\n",
    "        predict.predict_lexicographer(input_path =   '../resources/WSD_Evaluation_Framework/Evaluation_Datasets/{}/{}.data.xml'.format(name, name),\n",
    "                                      output_path = '../resources/WSD_Evaluation_Framework/Evaluation_Datasets/{}/{}.pred.lexicographer.txt'.format(name, name),\n",
    "                                      resources_path = resources_path)\n",
    "    if Basic_model.perform:\n",
    "        bashCommand = \"sudo java Scorer {}/{}.gold.lexicographer.txt {}/{}.pred.lexicographer.txt\".format(name, name, name, name)\n",
    "    \n",
    "    \n",
    "    if MFS_baseline.build:\n",
    "        predict.MFS_predict_writer(input_path =   '../resources/WSD_Evaluation_Framework/Evaluation_Datasets/{}/{}.data.xml'.format(name, name),\n",
    "                                   output_path = '../resources/WSD_Evaluation_Framework/Evaluation_Datasets/{}/MFS.{}.pred.lexicographer.txt'.format(name, name),\n",
    "                                   resources_path = resources_path,\n",
    "                                   prediction_type = 'lexicographer')\n",
    "    if MFS_baseline.perform:\n",
    "        bashCommand = \"sudo java Scorer {}/{}.gold.lexicographer.txt {}/MFS.{}.pred.lexicographer.txt\".format(name, name, name, name)    \n",
    "        \n",
    "    \n",
    "    ########################################################\n",
    "    os.chdir(\"../resources/WSD_Evaluation_Framework/Evaluation_Datasets/\")\n",
    "   \n",
    "    process = subprocess.Popen(bashCommand.split(), stdout=subprocess.PIPE)\n",
    "    output, error = process.communicate()\n",
    "    scores['lexicographer'][name] = float(output.decode(\"UTF-8\").split(\"\\n\")[0].split(\"\\t\")[1].split(\"%\")[0])\n",
    "    print(\"lexicographer: {}\".format(name))\n",
    "    for i in output.decode(\"UTF-8\").split(\"\\n\"):\n",
    "        print(i)\n",
    "    os.chdir(\"../../../code\")\n",
    "    ########################################################\n",
    "    print(\"_\"*50)\n",
    "    print(\"_\"*50)\n",
    "    print(\"_\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>babelnet</th>\n",
       "      <th>lexicographer</th>\n",
       "      <th>wordnet_domains</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>semeval2007</th>\n",
       "      <td>37.1</td>\n",
       "      <td>43.7</td>\n",
       "      <td>71.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>semeval2015</th>\n",
       "      <td>44.3</td>\n",
       "      <td>54.6</td>\n",
       "      <td>68.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>senseval2</th>\n",
       "      <td>49.3</td>\n",
       "      <td>58.8</td>\n",
       "      <td>76.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>senseval3</th>\n",
       "      <td>47.9</td>\n",
       "      <td>55.5</td>\n",
       "      <td>70.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             babelnet  lexicographer  wordnet_domains\n",
       "semeval2007      37.1           43.7             71.6\n",
       "semeval2015      44.3           54.6             68.7\n",
       "senseval2        49.3           58.8             76.8\n",
       "senseval3        47.9           55.5             70.8"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MFS_scores = pd.DataFrame(scores)\n",
    "MFS_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>babelnet</th>\n",
       "      <th>lexicographer</th>\n",
       "      <th>wordnet_domains</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>semeval2007</th>\n",
       "      <td>34.3</td>\n",
       "      <td>40.9</td>\n",
       "      <td>73.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>semeval2015</th>\n",
       "      <td>41.2</td>\n",
       "      <td>52.7</td>\n",
       "      <td>71.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>senseval2</th>\n",
       "      <td>46.6</td>\n",
       "      <td>56.6</td>\n",
       "      <td>77.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>senseval3</th>\n",
       "      <td>43.1</td>\n",
       "      <td>51.3</td>\n",
       "      <td>72.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             babelnet  lexicographer  wordnet_domains\n",
       "semeval2007      34.3           40.9             73.2\n",
       "semeval2015      41.2           52.7             71.3\n",
       "senseval2        46.6           56.6             77.8\n",
       "senseval3        43.1           51.3             72.2"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basicModel_scores = pd.DataFrame(scores)\n",
    "basicModel_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>babelnet</th>\n",
       "      <th>lexicographer</th>\n",
       "      <th>wordnet_domains</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>semeval2007</th>\n",
       "      <td>37.1</td>\n",
       "      <td>43.7</td>\n",
       "      <td>71.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>semeval2007</th>\n",
       "      <td>34.3</td>\n",
       "      <td>40.9</td>\n",
       "      <td>73.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>semeval2015</th>\n",
       "      <td>44.3</td>\n",
       "      <td>54.6</td>\n",
       "      <td>68.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>semeval2015</th>\n",
       "      <td>41.2</td>\n",
       "      <td>52.7</td>\n",
       "      <td>71.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>senseval2</th>\n",
       "      <td>49.3</td>\n",
       "      <td>58.8</td>\n",
       "      <td>76.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>senseval2</th>\n",
       "      <td>46.6</td>\n",
       "      <td>56.6</td>\n",
       "      <td>77.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>senseval3</th>\n",
       "      <td>47.9</td>\n",
       "      <td>55.5</td>\n",
       "      <td>70.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>senseval3</th>\n",
       "      <td>43.1</td>\n",
       "      <td>51.3</td>\n",
       "      <td>72.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             babelnet  lexicographer  wordnet_domains\n",
       "semeval2007      37.1           43.7             71.6\n",
       "semeval2007      34.3           40.9             73.2\n",
       "semeval2015      44.3           54.6             68.7\n",
       "semeval2015      41.2           52.7             71.3\n",
       "senseval2        49.3           58.8             76.8\n",
       "senseval2        46.6           56.6             77.8\n",
       "senseval3        47.9           55.5             70.8\n",
       "senseval3        43.1           51.3             72.2"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([MFS_scores,basicModel_scores]).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
