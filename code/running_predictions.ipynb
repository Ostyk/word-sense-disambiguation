{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import predict\n",
    "import os\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['semeval2007', 'semeval2015', 'senseval2', 'senseval3']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_ = \"../resources/WSD_Evaluation_Framework/Evaluation_Datasets\"\n",
    "eval_datasets = sorted([i for i in os.listdir(dir_) if i.startswith(\"se\")])\n",
    "resources_path = '../resources'\n",
    "del eval_datasets[1]\n",
    "eval_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(b'', None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bashCommand = \"sudo javac ../resources/WSD_Evaluation_Framework/Evaluation_Datasets/Scorer.java\"\n",
    "process = subprocess.Popen(bashCommand.split(), stdout=subprocess.PIPE)\n",
    "output, error = process.communicate()\n",
    "output,error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'babelnet': {'semeval2007': None,\n",
       "  'semeval2015': None,\n",
       "  'senseval2': None,\n",
       "  'senseval3': None},\n",
       " 'lexicographer': {'semeval2007': None,\n",
       "  'semeval2015': None,\n",
       "  'senseval2': None,\n",
       "  'senseval3': None},\n",
       " 'wordnet_domains': {'semeval2007': None,\n",
       "  'semeval2015': None,\n",
       "  'senseval2': None,\n",
       "  'senseval3': None}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = {\"babelnet\": {}, 'wordnet_domains': {}, 'lexicographer': {}}\n",
    "for name in eval_datasets:\n",
    "    for key in list(scores.keys()):\n",
    "        scores[key].update({name:None})\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: semeval2007\n",
      "\n",
      "../resources/WSD_Evaluation_Framework/Evaluation_Datasets/semeval2007/semeval2007.data.xml\n",
      "__________________________________________________\n",
      "babelnet: semeval2007\n",
      "P=\t32.1%\n",
      "R=\t32.1%\n",
      "F1=\t32.1%\n",
      "\n",
      "__________________________________________________\n",
      "wordnet_domains: semeval2007\n",
      "P=\t75.8%\n",
      "R=\t75.8%\n",
      "F1=\t75.8%\n",
      "\n",
      "__________________________________________________\n",
      "lexicographer: semeval2007\n",
      "P=\t39.8%\n",
      "R=\t39.8%\n",
      "F1=\t39.8%\n",
      "\n",
      "__________________________________________________\n",
      "__________________________________________________\n",
      "__________________________________________________\n",
      "Dataset: semeval2015\n",
      "\n",
      "../resources/WSD_Evaluation_Framework/Evaluation_Datasets/semeval2015/semeval2015.data.xml\n",
      "__________________________________________________\n",
      "babelnet: semeval2015\n",
      "P=\t39.9%\n",
      "R=\t39.9%\n",
      "F1=\t39.9%\n",
      "\n",
      "__________________________________________________\n",
      "wordnet_domains: semeval2015\n",
      "P=\t69.7%\n",
      "R=\t69.7%\n",
      "F1=\t69.7%\n",
      "\n",
      "__________________________________________________\n",
      "lexicographer: semeval2015\n",
      "P=\t50.3%\n",
      "R=\t50.3%\n",
      "F1=\t50.3%\n",
      "\n",
      "__________________________________________________\n",
      "__________________________________________________\n",
      "__________________________________________________\n",
      "Dataset: senseval2\n",
      "\n",
      "../resources/WSD_Evaluation_Framework/Evaluation_Datasets/senseval2/senseval2.data.xml\n",
      "__________________________________________________\n",
      "babelnet: senseval2\n",
      "P=\t46.7%\n",
      "R=\t46.7%\n",
      "F1=\t46.7%\n",
      "\n",
      "__________________________________________________\n",
      "wordnet_domains: senseval2\n",
      "P=\t78.8%\n",
      "R=\t78.8%\n",
      "F1=\t78.8%\n",
      "\n",
      "__________________________________________________\n",
      "lexicographer: senseval2\n",
      "P=\t56.4%\n",
      "R=\t56.4%\n",
      "F1=\t56.4%\n",
      "\n",
      "__________________________________________________\n",
      "__________________________________________________\n",
      "__________________________________________________\n",
      "Dataset: senseval3\n",
      "\n",
      "../resources/WSD_Evaluation_Framework/Evaluation_Datasets/senseval3/senseval3.data.xml\n",
      "__________________________________________________\n",
      "babelnet: senseval3\n",
      "P=\t43.2%\n",
      "R=\t43.2%\n",
      "F1=\t43.2%\n",
      "\n",
      "__________________________________________________\n",
      "wordnet_domains: senseval3\n",
      "P=\t73.5%\n",
      "R=\t73.5%\n",
      "F1=\t73.5%\n",
      "\n",
      "__________________________________________________\n",
      "lexicographer: senseval3\n",
      "P=\t51.0%\n",
      "R=\t51.0%\n",
      "F1=\t51.0%\n",
      "\n",
      "__________________________________________________\n",
      "__________________________________________________\n",
      "__________________________________________________\n"
     ]
    }
   ],
   "source": [
    "predict = False\n",
    "for name in eval_datasets:\n",
    "    print(\"Dataset: {}\\n\".format(name))\n",
    "    path = os.path.join(dir_, name)\n",
    "    xml_file = [i for i in os.listdir(path) if i.endswith('.xml')][0]\n",
    "    xml_file = os.path.join(path, xml_file)\n",
    "    print(xml_file)\n",
    "    print(\"_\"*50)\n",
    "    if predict:\n",
    "        predict.predict_babelnet(input_path =   '../resources/WSD_Evaluation_Framework/Evaluation_Datasets/{}/{}.data.xml'.format(name, name),\n",
    "                                 output_path = '../resources/WSD_Evaluation_Framework/Evaluation_Datasets/{}/{}.pred.babelnet.txt'.format(name, name),\n",
    "                                 resources_path = resources_path)\n",
    "    ########################################################\n",
    "    os.chdir(\"../resources/WSD_Evaluation_Framework/Evaluation_Datasets/\")\n",
    "    bashCommand = \"sudo java Scorer {}/{}.gold.babelnet.txt {}/{}.pred.babelnet.txt\".format(name, name, name, name)\n",
    "    process = subprocess.Popen(bashCommand.split(), stdout=subprocess.PIPE)\n",
    "    output, error = process.communicate()\n",
    "    scores['babelnet'][name] = float(output.decode(\"UTF-8\").split(\"\\n\")[0].split(\"\\t\")[1].split(\"%\")[0])\n",
    "    print(\"babelnet: {}\".format(name))\n",
    "    for i in output.decode(\"UTF-8\").split(\"\\n\"):\n",
    "        print(i)\n",
    "    os.chdir(\"../../../code\")\n",
    "    ########################################################\n",
    "    print(\"_\"*50)\n",
    "    if predict:\n",
    "        predict.predict_wordnet_domains(input_path =   '../resources/WSD_Evaluation_Framework/Evaluation_Datasets/{}/{}.data.xml'.format(name, name),\n",
    "                                        output_path = '../resources/WSD_Evaluation_Framework/Evaluation_Datasets/{}/{}.pred.wordnet_domains.txt'.format(name, name),\n",
    "                                        resources_path = resources_path)\n",
    "    ########################################################\n",
    "    os.chdir(\"../resources/WSD_Evaluation_Framework/Evaluation_Datasets/\")\n",
    "    bashCommand = \"sudo java Scorer {}/{}.gold.wordnet_domains.txt {}/{}.pred.wordnet_domains.txt\".format(name, name, name, name)\n",
    "    process = subprocess.Popen(bashCommand.split(), stdout=subprocess.PIPE)\n",
    "    output, error = process.communicate()\n",
    "    scores['wordnet_domains'][name] = float(output.decode(\"UTF-8\").split(\"\\n\")[0].split(\"\\t\")[1].split(\"%\")[0])\n",
    "    print(\"wordnet_domains: {}\".format(name))\n",
    "    for i in output.decode(\"UTF-8\").split(\"\\n\"):\n",
    "        print(i)\n",
    "    os.chdir(\"../../../code\")\n",
    "    ########################################################\n",
    "    print(\"_\"*50)\n",
    "    if predict:\n",
    "        predict.predict_lexicographer(input_path =   '../resources/WSD_Evaluation_Framework/Evaluation_Datasets/{}/{}.data.xml'.format(name, name),\n",
    "                                      output_path = '../resources/WSD_Evaluation_Framework/Evaluation_Datasets/{}/{}.pred.lexicographer.txt'.format(name, name),\n",
    "                                      resources_path = resources_path)\n",
    "    \n",
    "    ########################################################\n",
    "    os.chdir(\"../resources/WSD_Evaluation_Framework/Evaluation_Datasets/\")\n",
    "    bashCommand = \"sudo java Scorer {}/{}.gold.lexicographer.txt {}/{}.pred.lexicographer.txt\".format(name, name, name, name)\n",
    "    process = subprocess.Popen(bashCommand.split(), stdout=subprocess.PIPE)\n",
    "    output, error = process.communicate()\n",
    "    scores['lexicographer'][name] = float(output.decode(\"UTF-8\").split(\"\\n\")[0].split(\"\\t\")[1].split(\"%\")[0])\n",
    "    print(\"lexicographer: {}\".format(name))\n",
    "    for i in output.decode(\"UTF-8\").split(\"\\n\"):\n",
    "        print(i)\n",
    "    os.chdir(\"../../../code\")\n",
    "    ########################################################\n",
    "    print(\"_\"*50)\n",
    "    print(\"_\"*50)\n",
    "    print(\"_\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>babelnet</th>\n",
       "      <th>lexicographer</th>\n",
       "      <th>wordnet_domains</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>semeval2007</th>\n",
       "      <td>32.1</td>\n",
       "      <td>39.8</td>\n",
       "      <td>75.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>semeval2015</th>\n",
       "      <td>39.9</td>\n",
       "      <td>50.3</td>\n",
       "      <td>69.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>senseval2</th>\n",
       "      <td>46.7</td>\n",
       "      <td>56.4</td>\n",
       "      <td>78.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>senseval3</th>\n",
       "      <td>43.2</td>\n",
       "      <td>51.0</td>\n",
       "      <td>73.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             babelnet  lexicographer  wordnet_domains\n",
       "semeval2007      32.1           39.8             75.8\n",
       "semeval2015      39.9           50.3             69.7\n",
       "senseval2        46.7           56.4             78.8\n",
       "senseval3        43.2           51.0             73.5"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'babelnet': {'semeval2007': 32.1,\n",
       "  'semeval2015': 39.9,\n",
       "  'senseval2': 46.7,\n",
       "  'senseval3': 43.2},\n",
       " 'lexicographer': {'semeval2007': 39.8,\n",
       "  'semeval2015': 50.3,\n",
       "  'senseval2': 56.4,\n",
       "  'senseval3': 51.0},\n",
       " 'semeval2007': [],\n",
       " 'semeval2015': [],\n",
       " 'senseval2': [],\n",
       " 'senseval3': [],\n",
       " 'wordnet_domains': {'semeval2007': 75.8,\n",
       "  'semeval2015': 69.7,\n",
       "  'senseval2': 78.8,\n",
       "  'senseval3': 73.5}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
