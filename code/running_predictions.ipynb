{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import predict\n",
    "import os\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_ = \"../resources/WSD_Evaluation_Framework/Evaluation_Datasets\"\n",
    "eval_datasets = sorted([i for i in os.listdir(dir_) if i.startswith(\"se\")])\n",
    "resources_path = '../resources'\n",
    "del eval_datasets[1]\n",
    "eval_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bashCommand = \"sudo javac ../resources/WSD_Evaluation_Framework/Evaluation_Datasets/Scorer.java\"\n",
    "process = subprocess.Popen(bashCommand.split(), stdout=subprocess.PIPE)\n",
    "output, error = process.communicate()\n",
    "output,error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {\"babelnet\": {}, 'wordnet_domains': {}, 'lexicographer': {}}\n",
    "for name in eval_datasets:\n",
    "    for key in list(scores.keys()):\n",
    "        scores[key].update({name:None})\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_predictions = False\n",
    "\n",
    "MFS_baseline = True\n",
    "\n",
    "\n",
    "#assert not (perform_predictions and MFS_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in eval_datasets:\n",
    "    print(\"Dataset: {}\\n\".format(name))\n",
    "    path = os.path.join(dir_, name)\n",
    "    xml_file = [i for i in os.listdir(path) if i.endswith('.xml')][0]\n",
    "    xml_file = os.path.join(path, xml_file)\n",
    "    print(xml_file)\n",
    "    print(\"_\"*50)\n",
    "    if perform_predictions:\n",
    "        predict.predict_babelnet(input_path =   '../resources/WSD_Evaluation_Framework/Evaluation_Datasets/{}/{}.data.xml'.format(name, name),\n",
    "                                 output_path = '../resources/WSD_Evaluation_Framework/Evaluation_Datasets/{}/{}.pred.babelnet.txt'.format(name, name),\n",
    "                                 resources_path = resources_path)\n",
    "        bashCommand = \"sudo java Scorer {}/{}.gold.babelnet.txt {}/{}.pred.babelnet.txt\".format(name, name, name, name)\n",
    "    if MFS_baseline:\n",
    "        predict.MFS_predict_writer(input_path =   '../resources/WSD_Evaluation_Framework/Evaluation_Datasets/{}/{}.data.xml'.format(name, name),\n",
    "                                   output_path = '../resources/WSD_Evaluation_Framework/Evaluation_Datasets/{}/MFS.{}.pred.babelnet.txt'.format(name, name),\n",
    "                                   resources_path = resources_path,\n",
    "                                   prediction_type = 'babelnet')\n",
    "        bashCommand = \"sudo java Scorer {}/{}.gold.babelnet.txt {}/MFS.{}.pred.babelnet.txt\".format(name, name, name, name)\n",
    "    ########################################################\n",
    "    os.chdir(\"../resources/WSD_Evaluation_Framework/Evaluation_Datasets/\")\n",
    "    process = subprocess.Popen(bashCommand.split(), stdout=subprocess.PIPE)\n",
    "    output, error = process.communicate()\n",
    "    scores['babelnet'][name] = float(output.decode(\"UTF-8\").split(\"\\n\")[0].split(\"\\t\")[1].split(\"%\")[0])\n",
    "    print(\"babelnet: {}\".format(name))\n",
    "    for i in output.decode(\"UTF-8\").split(\"\\n\"):\n",
    "        print(i)\n",
    "    os.chdir(\"../../../code\")\n",
    "    \n",
    "    ########################################################\n",
    "    ########################################################\n",
    "    ########################################################\n",
    "    \n",
    "    print(\"_\"*50)\n",
    "    if perform_predictions:\n",
    "        predict.predict_wordnet_domains(input_path =   '../resources/WSD_Evaluation_Framework/Evaluation_Datasets/{}/{}.data.xml'.format(name, name),\n",
    "                                        output_path = '../resources/WSD_Evaluation_Framework/Evaluation_Datasets/{}/{}.pred.wordnet_domains.txt'.format(name, name),\n",
    "                                        resources_path = resources_path)\n",
    "        bashCommand = \"sudo java Scorer {}/{}.gold.wordnet_domains.txt {}/{}.pred.wordnet_domains.txt\".format(name, name, name, name)\n",
    "    \n",
    "    if MFS_baseline:\n",
    "        predict.MFS_predict_writer(input_path =   '../resources/WSD_Evaluation_Framework/Evaluation_Datasets/{}/{}.data.xml'.format(name, name),\n",
    "                                   output_path = '../resources/WSD_Evaluation_Framework/Evaluation_Datasets/{}/MFS.{}.pred.wordnet_domains.txt'.format(name, name),\n",
    "                                   resources_path = resources_path,\n",
    "                                   prediction_type = 'wordnet_domains')\n",
    "        bashCommand = \"sudo java Scorer {}/{}.gold.wordnet_domains.txt {}/MFS.{}.pred.wordnet_domains.txt\".format(name, name, name, name)    \n",
    "        \n",
    "        \n",
    "    ########################################################\n",
    "    os.chdir(\"../resources/WSD_Evaluation_Framework/Evaluation_Datasets/\")\n",
    "    process = subprocess.Popen(bashCommand.split(), stdout=subprocess.PIPE)\n",
    "    output, error = process.communicate()\n",
    "    scores['wordnet_domains'][name] = float(output.decode(\"UTF-8\").split(\"\\n\")[0].split(\"\\t\")[1].split(\"%\")[0])\n",
    "    print(\"wordnet_domains: {}\".format(name))\n",
    "    for i in output.decode(\"UTF-8\").split(\"\\n\"):\n",
    "        print(i)\n",
    "    os.chdir(\"../../../code\")\n",
    "    \n",
    "    ########################################################\n",
    "    ########################################################\n",
    "    ########################################################\n",
    "    print(\"_\"*50)\n",
    "    if perform_predictions:\n",
    "        predict.predict_lexicographer(input_path =   '../resources/WSD_Evaluation_Framework/Evaluation_Datasets/{}/{}.data.xml'.format(name, name),\n",
    "                                      output_path = '../resources/WSD_Evaluation_Framework/Evaluation_Datasets/{}/{}.pred.lexicographer.txt'.format(name, name),\n",
    "                                      resources_path = resources_path)\n",
    "        bashCommand = \"sudo java Scorer {}/{}.gold.lexicographer.txt {}/{}.pred.lexicographer.txt\".format(name, name, name, name)\n",
    "    \n",
    "    if MFS_baseline:\n",
    "        predict.MFS_predict_writer(input_path =   '../resources/WSD_Evaluation_Framework/Evaluation_Datasets/{}/{}.data.xml'.format(name, name),\n",
    "                                   output_path = '../resources/WSD_Evaluation_Framework/Evaluation_Datasets/{}/MFS.{}.pred.lexicographer.txt'.format(name, name),\n",
    "                                   resources_path = resources_path,\n",
    "                                   prediction_type = 'lexicographer')\n",
    "        bashCommand = \"sudo java Scorer {}/{}.gold.lexicographer.txt {}/MFS.{}.pred.lexicographer.txt\".format(name, name, name, name)    \n",
    "        \n",
    "    \n",
    "    ########################################################\n",
    "    os.chdir(\"../resources/WSD_Evaluation_Framework/Evaluation_Datasets/\")\n",
    "   \n",
    "    process = subprocess.Popen(bashCommand.split(), stdout=subprocess.PIPE)\n",
    "    output, error = process.communicate()\n",
    "    scores['lexicographer'][name] = float(output.decode(\"UTF-8\").split(\"\\n\")[0].split(\"\\t\")[1].split(\"%\")[0])\n",
    "    print(\"lexicographer: {}\".format(name))\n",
    "    for i in output.decode(\"UTF-8\").split(\"\\n\"):\n",
    "        print(i)\n",
    "    os.chdir(\"../../../code\")\n",
    "    ########################################################\n",
    "    print(\"_\"*50)\n",
    "    print(\"_\"*50)\n",
    "    print(\"_\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
