{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import predict\n",
    "import os\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['semeval2007', 'semeval2015', 'senseval2', 'senseval3']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_ = \"../resources/WSD_Evaluation_Framework/Evaluation_Datasets\"\n",
    "eval_datasets = sorted([i for i in os.listdir(dir_) if i.startswith(\"se\")])\n",
    "resources_path = '../resources'\n",
    "del eval_datasets[1]\n",
    "eval_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(b'', None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bashCommand = \"sudo javac ../resources/WSD_Evaluation_Framework/Evaluation_Datasets/Scorer.java\"\n",
    "process = subprocess.Popen(bashCommand.split(), stdout=subprocess.PIPE)\n",
    "output, error = process.communicate()\n",
    "output,error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'babelnet': {'semeval2007': None,\n",
       "  'semeval2015': None,\n",
       "  'senseval2': None,\n",
       "  'senseval3': None},\n",
       " 'lexicographer': {'semeval2007': None,\n",
       "  'semeval2015': None,\n",
       "  'senseval2': None,\n",
       "  'senseval3': None},\n",
       " 'wordnet_domains': {'semeval2007': None,\n",
       "  'semeval2015': None,\n",
       "  'senseval2': None,\n",
       "  'senseval3': None}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = {\"babelnet\": {}, 'wordnet_domains': {}, 'lexicographer': {}}\n",
    "for name in eval_datasets:\n",
    "    for key in list(scores.keys()):\n",
    "        scores[key].update({name:None})\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = namedtuple(\"predictions\", \"build perform\")\n",
    "\n",
    "Basic_model = record(True, True)\n",
    "\n",
    "MFS_baseline = record(False, False)\n",
    "\n",
    "task = 'Multitask'\n",
    "#assert not (perform_predictions and MFS_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: semeval2007\n",
      "\n",
      "../resources/WSD_Evaluation_Framework/Evaluation_Datasets/semeval2007/semeval2007.data.xml\n",
      "__________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "batch: : 3it [00:09,  3.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done writing to:\t../resources/WSD_Evaluation_Framework/Evaluation_Datasets/semeval2007/semeval2007.pred.babelnet.Multitask.txt\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-eece340924c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mprocess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbashCommand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'babelnet'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"UTF-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"babelnet: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"UTF-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for name in eval_datasets:\n",
    "    print(\"Dataset: {}\\n\".format(name))\n",
    "    path = os.path.join(dir_, name)\n",
    "    xml_file = [i for i in os.listdir(path) if i.endswith('.xml')][0]\n",
    "    xml_file = os.path.join(path, xml_file)\n",
    "    print(xml_file)\n",
    "    print(\"_\"*50)\n",
    "    if Basic_model.build:\n",
    "        predict.predict_babelnet(input_path =   '../resources/WSD_Evaluation_Framework/Evaluation_Datasets/{}/{}.data.xml'.format(name, name),\n",
    "                                 output_path = '../resources/WSD_Evaluation_Framework/Evaluation_Datasets/{}/{}.pred.babelnet.{}.txt'.format(name, name, task),\n",
    "                                 resources_path = resources_path)\n",
    "    if Basic_model.perform:\n",
    "        bashCommand = \"sudo java Scorer {}/{}.gold.babelnet.txt {}/{}.pred.babelnet2.txt\".format(name, name, name, name)\n",
    "    if MFS_baseline.build:\n",
    "        predict.MFS_predict_writer(input_path =   '../resources/WSD_Evaluation_Framework/Evaluation_Datasets/{}/{}.data.xml'.format(name, name),\n",
    "                                   output_path = '../resources/WSD_Evaluation_Framework/Evaluation_Datasets/{}/MFS.{}.pred.babelnet.{}.txt'.format(name, name, task),\n",
    "                                   resources_path = resources_path,\n",
    "                                   prediction_type = 'babelnet')\n",
    "    if MFS_baseline.perform:\n",
    "        bashCommand = \"sudo java Scorer {}/{}.gold.babelnet.txt {}/MFS.{}.pred.babelnet.{}.txt\".format(name, name, name, name, task)\n",
    "    ########################################################\n",
    "    os.chdir(\"../resources/WSD_Evaluation_Framework/Evaluation_Datasets/\")\n",
    "    process = subprocess.Popen(bashCommand.split(), stdout=subprocess.PIPE)\n",
    "    output, error = process.communicate()\n",
    "    scores['babelnet'][name] = float(output.decode(\"UTF-8\").split(\"\\n\")[0].split(\"\\t\")[1].split(\"%\")[0])\n",
    "    print(\"babelnet: {}\".format(name))\n",
    "    for i in output.decode(\"UTF-8\").split(\"\\n\"):\n",
    "        print(i)\n",
    "    os.chdir(\"../../../code\")\n",
    "    \n",
    "    ########################################################\n",
    "    ########################################################\n",
    "    ########################################################\n",
    "    \n",
    "    print(\"_\"*50)\n",
    "    if Basic_model.build:\n",
    "        predict.predict_wordnet_domains(input_path =   '../resources/WSD_Evaluation_Framework/Evaluation_Datasets/{}/{}.data.xml'.format(name, name),\n",
    "                                        output_path = '../resources/WSD_Evaluation_Framework/Evaluation_Datasets/{}/{}.pred.wordnet_domains.{}..txt'.format(name, name, task),\n",
    "                                        resources_path = resources_path)\n",
    "    if Basic_model.perform:\n",
    "        bashCommand = \"sudo java Scorer {}/{}.gold.wordnet_domains.txt {}/{}.pred.wordnet_domains2.txt\".format(name, name, name, name)\n",
    "    \n",
    "    if MFS_baseline.build:\n",
    "        predict.MFS_predict_writer(input_path =   '../resources/WSD_Evaluation_Framework/Evaluation_Datasets/{}/{}.data.xml'.format(name, name),\n",
    "                                   output_path = '../resources/WSD_Evaluation_Framework/Evaluation_Datasets/{}/MFS.{}.pred.wordnet_domain.{}.txt'.format(name, name, task),\n",
    "                                   resources_path = resources_path,\n",
    "                                   prediction_type = 'wordnet_domains')\n",
    "    if MFS_baseline.perform:\n",
    "        bashCommand = \"sudo java Scorer {}/{}.gold.wordnet_domains.txt {}/MFS.{}.pred.wordnet_domains.{}.txt\".format(name, name, name, name, task)    \n",
    "        \n",
    "        \n",
    "    ########################################################\n",
    "    os.chdir(\"../resources/WSD_Evaluation_Framework/Evaluation_Datasets/\")\n",
    "    process = subprocess.Popen(bashCommand.split(), stdout=subprocess.PIPE)\n",
    "    output, error = process.communicate()\n",
    "    scores['wordnet_domains'][name] = float(output.decode(\"UTF-8\").split(\"\\n\")[0].split(\"\\t\")[1].split(\"%\")[0])\n",
    "    print(\"wordnet_domains: {}\".format(name))\n",
    "    for i in output.decode(\"UTF-8\").split(\"\\n\"):\n",
    "        print(i)\n",
    "    os.chdir(\"../../../code\")\n",
    "    \n",
    "    ########################################################\n",
    "    ########################################################\n",
    "    ########################################################\n",
    "    print(\"_\"*50)\n",
    "    if Basic_model.build:\n",
    "        predict.predict_lexicographer(input_path =   '../resources/WSD_Evaluation_Framework/Evaluation_Datasets/{}/{}.data.xml'.format(name, name),\n",
    "                                      output_path = '../resources/WSD_Evaluation_Framework/Evaluation_Datasets/{}/{}.pred.lexicographer.{}..txt'.format(name, name, task),\n",
    "                                      resources_path = resources_path)\n",
    "    if Basic_model.perform:\n",
    "        bashCommand = \"sudo java Scorer {}/{}.gold.lexicographer.txt {}/{}.pred.lexicographer2.txt\".format(name, name, name, name)\n",
    "    \n",
    "    \n",
    "    if MFS_baseline.build:\n",
    "        predict.MFS_predict_writer(input_path =   '../resources/WSD_Evaluation_Framework/Evaluation_Datasets/{}/{}.data.xml'.format(name, name),\n",
    "                                   output_path = '../resources/WSD_Evaluation_Framework/Evaluation_Datasets/{}/MFS.{}.pred.lexicographer.{}..txt'.format(name, name, task),\n",
    "                                   resources_path = resources_path,\n",
    "                                   prediction_type = 'lexicographer')\n",
    "    if MFS_baseline.perform:\n",
    "        bashCommand = \"sudo java Scorer {}/{}.gold.lexicographer.txt {}/MFS.{}.pred.lexicographer.{}..txt\".format(name, name, name, name, task)    \n",
    "        \n",
    "    \n",
    "    ########################################################\n",
    "    os.chdir(\"../resources/WSD_Evaluation_Framework/Evaluation_Datasets/\")\n",
    "   \n",
    "    process = subprocess.Popen(bashCommand.split(), stdout=subprocess.PIPE)\n",
    "    output, error = process.communicate()\n",
    "    scores['lexicographer'][name] = float(output.decode(\"UTF-8\").split(\"\\n\")[0].split(\"\\t\")[1].split(\"%\")[0])\n",
    "    print(\"lexicographer: {}\".format(name))\n",
    "    for i in output.decode(\"UTF-8\").split(\"\\n\"):\n",
    "        print(i)\n",
    "    os.chdir(\"../../../code\")\n",
    "    ########################################################\n",
    "    print(\"_\"*50)\n",
    "    print(\"_\"*50)\n",
    "    print(\"_\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>babelnet</th>\n",
       "      <th>lexicographer</th>\n",
       "      <th>wordnet_domains</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>semeval2007</th>\n",
       "      <td>37.1</td>\n",
       "      <td>43.7</td>\n",
       "      <td>71.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>semeval2015</th>\n",
       "      <td>44.3</td>\n",
       "      <td>54.6</td>\n",
       "      <td>68.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>senseval2</th>\n",
       "      <td>49.3</td>\n",
       "      <td>58.8</td>\n",
       "      <td>76.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>senseval3</th>\n",
       "      <td>47.9</td>\n",
       "      <td>55.5</td>\n",
       "      <td>70.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             babelnet  lexicographer  wordnet_domains\n",
       "semeval2007      37.1           43.7             71.6\n",
       "semeval2015      44.3           54.6             68.7\n",
       "senseval2        49.3           58.8             76.8\n",
       "senseval3        47.9           55.5             70.8"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MFS_scores = pd.DataFrame(scores)\n",
    "MFS_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>babelnet</th>\n",
       "      <th>lexicographer</th>\n",
       "      <th>wordnet_domains</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>semeval2007</th>\n",
       "      <td>35.8</td>\n",
       "      <td>42.9</td>\n",
       "      <td>73.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>semeval2015</th>\n",
       "      <td>42.6</td>\n",
       "      <td>52.7</td>\n",
       "      <td>70.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>senseval2</th>\n",
       "      <td>47.8</td>\n",
       "      <td>57.6</td>\n",
       "      <td>77.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>senseval3</th>\n",
       "      <td>45.5</td>\n",
       "      <td>52.8</td>\n",
       "      <td>72.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             babelnet  lexicographer  wordnet_domains\n",
       "semeval2007      35.8           42.9             73.6\n",
       "semeval2015      42.6           52.7             70.2\n",
       "senseval2        47.8           57.6             77.7\n",
       "senseval3        45.5           52.8             72.4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basicModel_scores = pd.DataFrame(scores)\n",
    "basicModel_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([MFS_scores,basicModel_scores]).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
