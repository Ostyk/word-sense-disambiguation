{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_file_path = '../resources/WSD_Evaluation_Framework/Training_Corpora/SemCor/semcor.data.xml'\n",
    "gold_file_path =  '../resources/WSD_Evaluation_Framework/Training_Corpora/SemCor/semcor.gold.key.txt'\n",
    "\n",
    "training_file_path = '../resources/WSD_Evaluation_Framework/Evaluation_Datasets/semeval2007/semeval2007.data.xml'\n",
    "gold_file_path = '../resources/WSD_Evaluation_Framework/Evaluation_Datasets/semeval2007/semeval2007.gold.key.txt'\n",
    "\n",
    "training_file_path_dev = '../resources/WSD_Evaluation_Framework/Evaluation_Datasets/semeval2013/semeval2013.data.xml'\n",
    "gold_file_path_dev = '../resources/WSD_Evaluation_Framework/Evaluation_Datasets/semeval2013/semeval2013.gold.key.txt'\n",
    "fine_senses_vocab_path = '../resources/semcor.vocab.WordNet.json'\n",
    "input_vocab_path = '../resources/semcor.input.vocab.json'\n",
    "input_antivocab_path = '../resources/semcor.leftout.vocab.json'\n",
    "embedding_size = 32\n",
    "batch_size = 64\n",
    "LEARNING_RATE = 0.01\n",
    "N_EPOCHS = 10\n",
    "PADDING_SIZE = 50\n",
    "print_model = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models\n",
    "import utils\n",
    "import generators\n",
    "import generatorsCopy\n",
    "\n",
    "from tensorflow.random import set_random_seed\n",
    "set_random_seed(42)\n",
    "import tensorflow.keras as K\n",
    "#import keras as K\n",
    "import time\n",
    "import os\n",
    "#from tqdm import tqdm\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from tqdm import  tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading dict\n",
    "senses = utils.json_vocab_reader(fine_senses_vocab_path)\n",
    "inputs, antivocab = utils.json_vocab_reader(input_vocab_path, input_antivocab_path)\n",
    "output_vocab = utils.vocab_merge(senses, inputs)\n",
    "reverse_output_vocab =  dict((v, k) for k, v in output_vocab.items())\n",
    "\n",
    "K.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = models.Basic(test=2)\n",
    "BasicModelNetwork = models.Basic(vocab_size = len(output_vocab),\n",
    "                                embedding_size = embedding_size,\n",
    "                                hidden_size = 32,\n",
    "                                PADDING_SIZE = PADDING_SIZE,\n",
    "                                LEARNING_RATE = LEARNING_RATE,\n",
    "                                INPUT_DROPOUT = 0.2,\n",
    "                                LSTM_DROPOUT = 0.45,\n",
    "                                RECURRENT_DROPOUT = 0.35,\n",
    "                                N_EPOCHS = N_EPOCHS)\n",
    "\n",
    "if print_model is True:\n",
    "    BasicModelNetwork.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generators.Basic(batch_size = 64,\n",
    "                                training_file_path = training_file_path,\n",
    "                                gold_file_path = gold_file_path,\n",
    "                                antivocab = antivocab,\n",
    "                                output_vocab = output_vocab,\n",
    "                                PADDING_SIZE = PADDING_SIZE)\n",
    "\n",
    "validation_generator = generators.Basic(batch_size = 64,\n",
    "                                         training_file_path = training_file_path_dev,\n",
    "                                         gold_file_path = gold_file_path_dev,\n",
    "                                         antivocab = antivocab,\n",
    "                                         output_vocab = output_vocab,\n",
    "                                         PADDING_SIZE = PADDING_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0906 14:18:20.617034 140072756623104 callbacks.py:875] `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('../resources/logging'):\n",
    "    os.mkdir('../resources/logging')\n",
    "model_name = time.strftime('%Y-%m-%d_%H:%M:%S_%z')\n",
    "cbk = K.callbacks.TensorBoard('../resources/logging/keras_model_'+model_name)\n",
    "\n",
    "early_stopping = K.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0,\n",
    "                              patience=3,\n",
    "                              verbose=2, mode='auto')\n",
    "csv_logger = K.callbacks.CSVLogger('../resources/logging/keras_model_'+model_name+'.log')\n",
    "model_checkpoint = K.callbacks.ModelCheckpoint(filepath = '../resources/logging/keras_model_'+model_name+'.h5',\n",
    "                                               monitor='val_precision',\n",
    "                                               verbose=2,\n",
    "                                               save_best_only=True,\n",
    "                                               save_weights_only=True,\n",
    "                                               mode='auto', period=1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for epoch in range(1, epochs+1):\n",
    "#     with tqdm(total=epochs) as epoch_bar:\n",
    "#         c1, c2 = [0,0], [0,0]\n",
    "#         epoch_bar.set_description(\"Epoch {}/{} loss: {:.3f}\\tacc: {:.3f}\\tval_loss: {:.3f}\\tval_acc: {:.3f}\".format(epoch, epochs, *c1, *c2))\n",
    "#         for batch_x, batch_y in train_generator.__getitem__():\n",
    "#             c1 = BasicModelNetwork.train_on_batch(batch_x, batch_y)\n",
    "#             epoch_bar.set_description(\"Epoch {}/{} loss: {:.3f}\\tacc: {:.3f}\\tval_loss: {:.3f}\\tval_acc: {:.3f}\".format(epoch, epochs, *c1, *c2))\n",
    "\n",
    "#         for batch_x, batch_y in validation_generator.__getitem__():\n",
    "#             c2 = BasicModelNetwork.test_on_batch(batch_x, batch_y)\n",
    "#             epoch_bar.set_description(\"Epoch {}/{} loss: {:.3f}\\tacc: {:.3f}\\tval_loss: {:.3f}\\tval_acc: {:.3f}\".format(epoch, epochs, *c1, *c2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmt = \"Epoch {}/{} loss: {:.3f}\\tacc: {:.3f}\\tval_loss: {:.3f}\\tval_acc: {:.3f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2 loss: 11.156\tacc: 0.466\tval_loss: 10.808\tval_acc: 0.490:   0%|          | 0/2 [00:07<?, ?it/s]\n",
      "Epoch 2/2 loss: 10.504\tacc: 0.596\tval_loss: 9.740\tval_acc: 0.489:   0%|          | 0/2 [00:02<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs+1):\n",
    "    with tqdm(total=epochs) as epoch_bar:\n",
    "    \n",
    "        c1, c2 = [0,0], [0,0]\n",
    "        epoch_bar.set_description(fmt.format(epoch, epochs, *c1, *c2))\n",
    "        \n",
    "        train_stats = {\"loss\": [], \"acc\": []}\n",
    "        \n",
    "        for batch_x, batch_y in train_generator.__getitem__():\n",
    "            c1 = BasicModelNetwork.train_on_batch(batch_x, batch_y)\n",
    "            epoch_bar.set_description(fmt.format(epoch, epochs, *c1, *c2))\n",
    "            train_stats['loss'].append(c1[0])\n",
    "            train_stats['acc'].append(c1[1])\n",
    "            \n",
    "        c1 = np.mean(train_stats['loss']), np.mean(train_stats['acc'])\n",
    "        epoch_bar.set_description(fmt.format(epoch, epochs, *c1, *c2))\n",
    "        \n",
    "        val_stats = {\"loss\": [], \"acc\": []}\n",
    "        \n",
    "        for batch_x, batch_y in validation_generator.__getitem__():\n",
    "            c2 = BasicModelNetwork.test_on_batch(batch_x, batch_y)\n",
    "            epoch_bar.set_description(fmt.format(epoch, epochs, *c1, *c2))\n",
    "            val_stats['loss'].append(c2[0])\n",
    "            val_stats['acc'].append(c2[1])\n",
    "        \n",
    "        c2 = np.mean(val_stats['loss']), np.mean(val_stats['acc'])\n",
    "        epoch_bar.set_description(fmt.format(epoch, epochs, *c1, *c2))\n",
    "            \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from six import next\n",
    "\n",
    "patience = 4\n",
    "best_loss = 1e6\n",
    "rounds_without_improvement = 0\n",
    "\n",
    "for epoch_nb in range(nb_of_epochs):\n",
    "    losses_list = list()\n",
    "    for batch in range(nb_of_batches):\n",
    "        x, y = next(train_data_gen)\n",
    "        losses_list.append(model.train_on_batch(x, y))\n",
    "    mean_loss = sum(losses_list) / len(losses_list)\n",
    "\n",
    "    if mean_loss < best_loss:\n",
    "        best_loss = mean_loss\n",
    "        rounds_witout_improvement = 0\n",
    "    else:\n",
    "        rounds_without_improvement +=1\n",
    "\n",
    "    if rounds_without_improvement == patience:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from six import next\n",
    "\n",
    "patience = 4\n",
    "best_loss = 1e6\n",
    "rounds_without_improvement = 0\n",
    "\n",
    "for epoch_nb in range(nb_of_epochs):\n",
    "    losses_list = list()\n",
    "    for batch in range(nb_of_batches):\n",
    "        x, y = next(train_data_gen)\n",
    "        losses_list.append(model.train_on_batch(x, y))\n",
    "    mean_loss = sum(losses_list) / len(losses_list)\n",
    "\n",
    "    if mean_loss < best_loss:\n",
    "        best_loss = mean_loss\n",
    "        rounds_witout_improvement = 0\n",
    "    else:\n",
    "        rounds_without_improvement +=1\n",
    "\n",
    "    if rounds_without_improvement == patience:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generatorsCopy.get(batch_size = 64,\n",
    "                                training_file_path = training_file_path,\n",
    "                                gold_file_path = gold_file_path,\n",
    "                                antivocab = antivocab,\n",
    "                                output_vocab = output_vocab,\n",
    "                                PADDING_SIZE = PADDING_SIZE)\n",
    "\n",
    "validation_generator = generatorsCopy.get(batch_size = 64,\n",
    "                                         training_file_path = training_file_path_dev,\n",
    "                                         gold_file_path = gold_file_path_dev,\n",
    "                                         antivocab = antivocab,\n",
    "                                         output_vocab = output_vocab,\n",
    "                                         PADDING_SIZE = PADDING_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in validation_generator:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BasicModelNetwork.fit_generator(train_generator, \n",
    "                                steps_per_epoch=None,\n",
    "                                epochs=1, \n",
    "                                verbose=3,\n",
    "                                callbacks=None,\n",
    "                                validation_data=validation_generator,\n",
    "                                validation_steps=None,\n",
    "                                validation_freq=1,\n",
    "                                class_weight=None,\n",
    "                                max_queue_size=10,\n",
    "                                workers=-1, \n",
    "                                use_multiprocessing=False,\n",
    "                                shuffle=False,\n",
    "                                initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    with tqdm(total=len(train_generator)) as pbar:\n",
    "        for batch_x, batch_y in train_generator.__getitem__():\n",
    "            c1 = BasicModelNetwork.train_on_batch(batch_x, batch_y)\n",
    "            pbar.set_description(\"Epoch {}/{}\\tloss: {:.3f} \\tacc: {:.3f}\".format(epoch, epochs, *c1))\n",
    "\n",
    "    with tqdm(total=len(validation_generator)) as pbar:\n",
    "        for batch_x, batch_y in validation_generator.__getitem__():\n",
    "            c2 = BasicModelNetwork.test_on_batch(batch_x, batch_y)\n",
    "            pbar.set_description(\"Epoch {}/{}\\tval_loss: {:.3f} \\tval_acc: {:.3f}\".format(epoch, epochs, *c2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
