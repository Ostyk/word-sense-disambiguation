{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_file_path = '../resources/WSD_Evaluation_Framework/Training_Corpora/SemCor/semcor.data.xml'\n",
    "gold_file_path =  '../resources/WSD_Evaluation_Framework/Training_Corpora/SemCor/semcor.gold.key.txt'\n",
    "\n",
    "training_file_path = '../resources/WSD_Evaluation_Framework/Evaluation_Datasets/semeval2013/semeval2013.data.xml'\n",
    "gold_file_path = '../resources/WSD_Evaluation_Framework/Evaluation_Datasets/semeval2013/semeval2013.gold.key.txt'\n",
    "\n",
    "training_file_path_dev = '../resources/WSD_Evaluation_Framework/Evaluation_Datasets/semeval2013/semeval2013.data.xml'\n",
    "gold_file_path_dev = '../resources/WSD_Evaluation_Framework/Evaluation_Datasets/semeval2013/semeval2013.gold.key.txt'\n",
    "fine_senses_vocab_path = '../resources/semcor.vocab.WordNet.json'\n",
    "input_vocab_path = '../resources/semcor.input.vocab.json'\n",
    "input_antivocab_path = '../resources/semcor.leftout.vocab.json'\n",
    "embedding_size = 32\n",
    "batch_size = 64\n",
    "LEARNING_RATE = 0.01\n",
    "N_EPOCHS = 10\n",
    "PADDING_SIZE = 50\n",
    "print_model = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import models\n",
    "import utils\n",
    "#from tensorflow.random import set_random_seed\n",
    "#set_random_seed(42)\n",
    "import tensorflow.keras as K\n",
    "#import keras as K\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading dict\n",
    "senses = utils.json_vocab_reader(fine_senses_vocab_path)\n",
    "inputs, antivocab = utils.json_vocab_reader(input_vocab_path, input_antivocab_path)\n",
    "output_vocab = utils.vocab_merge(senses, inputs)\n",
    "reverse_output_vocab =  dict((v, k) for k, v in output_vocab.items())\n",
    "\n",
    "K.backend.clear_session()\n",
    "model = models.Basic(test=2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating KERAS model\n"
     ]
    }
   ],
   "source": [
    "BasicModelNetwork = model.build(vocab_size = len(output_vocab),\n",
    "                                embedding_size = embedding_size,\n",
    "                                hidden_size = 32,\n",
    "                                PADDING_SIZE = PADDING_SIZE,\n",
    "                                LEARNING_RATE = LEARNING_RATE,\n",
    "                                INPUT_DROPOUT = 0.2,\n",
    "                                LSTM_DROPOUT = 0.45,\n",
    "                                RECURRENT_DROPOUT = 0.35,\n",
    "                                N_EPOCHS = N_EPOCHS)\n",
    "\n",
    "if print_model is True:\n",
    "    BasicModelNetwork.summary()\n",
    "\n",
    "\n",
    "train_generator = model.prepare_sentence_batch(batch_size = 64,\n",
    "                                                training_file_path = training_file_path,\n",
    "                                                gold_file_path = gold_file_path,\n",
    "                                                antivocab = antivocab,\n",
    "                                                output_vocab = output_vocab,\n",
    "                                                PADDING_SIZE = PADDING_SIZE)\n",
    "\n",
    "validation_generator = model.prepare_sentence_batch(batch_size = 64,\n",
    "                                                     training_file_path = training_file_path_dev,\n",
    "                                                     gold_file_path = gold_file_path_dev,\n",
    "                                                     antivocab = antivocab,\n",
    "                                                     output_vocab = output_vocab,\n",
    "                                                     PADDING_SIZE = PADDING_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('../resources/logging'):\n",
    "    os.mkdir('../resources/logging')\n",
    "model_name = time.strftime('%Y-%m-%d_%H:%M:%S_%z')\n",
    "cbk = K.callbacks.TensorBoard('../resources/logging/keras_model_'+model_name)\n",
    "\n",
    "early_stopping = K.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0,\n",
    "                              patience=3,\n",
    "                              verbose=2, mode='auto')\n",
    "csv_logger = K.callbacks.CSVLogger('../resources/logging/keras_model_'+model_name+'.log')\n",
    "model_checkpoint = K.callbacks.ModelCheckpoint(filepath = '../resources/logging/keras_model_'+model_name+'.h5',\n",
    "                                               monitor='val_precision',\n",
    "                                               verbose=2,\n",
    "                                               save_best_only=True,\n",
    "                                               save_weights_only=True,\n",
    "                                               mode='auto', period=1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "4/4 [==============================] - 11s 3s/step - loss: 10.9626 - acc: 0.6271\n",
      "4/4 [==============================] - 37s 9s/step - loss: 11.5299 - acc: 0.6418 - val_loss: 10.9626 - val_acc: 0.6271\n",
      "Epoch 2/5\n",
      "WARNING:tensorflow:Your dataset iterator ran out of data.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "0/4 [..............................] - ETA: 0s - loss: 0.0000e+00 - acc: 0.6418 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14db86588>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BasicModelNetwork.fit_generator(train_generator, \n",
    "                                steps_per_epoch=306//64,\n",
    "                                epochs=5, \n",
    "                                verbose=1,\n",
    "                                callbacks=[cbk, csv_logger, early_stopping],\n",
    "                                validation_data=validation_generator,\n",
    "                                validation_steps=306//64,\n",
    "                                class_weight=None,\n",
    "                                max_queue_size=10,\n",
    "                                workers=-1, \n",
    "                                use_multiprocessing=False,\n",
    "                                shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in train_generator:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q=0\n",
    "for x,y in tqdm(train_generator):\n",
    "    q+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "train_generator = model.prepare_sentence_batch(batch_size = batch_size,\n",
    "                                                training_file_path = training_file_path,\n",
    "                                                gold_file_path = gold_file_path,\n",
    "                                                antivocab = antivocab,\n",
    "                                                output_vocab = output_vocab,\n",
    "                                                PADDING_SIZE = PADDING_SIZE)\n",
    "\n",
    "\n",
    "for x,y in tqdm(train_generator):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'testing.npy'\n",
    "\n",
    "with open(filename, 'wb') as f:\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = model.prepare_sentence_batch(batch_size = 64,\n",
    "                               training_file_path = '../resources/WSD_Evaluation_Framework/Training_Corpora/SemCor/semcor.data.xml',\n",
    "                               gold_file_path =  '../resources/WSD_Evaluation_Framework/Training_Corpora/SemCor/semcor.gold.key.txt',\n",
    "                               antivocab = antivocab,\n",
    "                               output_vocab = output_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x,y in batch:\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y.reshape(*(y).shape,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.expand_dims(y, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "for x, y in tqdm(batch):\n",
    "    if c==10:\n",
    "        break\n",
    "    c+=1\n",
    "    print(c, x.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.__next__().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in tqdm(validation_generator):\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_file_path_dev = '../resources/WSD_Evaluation_Framework/Evaluation_Datasets/semeval2007/semeval2007.data.xml'\n",
    "gold_file_path_dev = '../resources/WSD_Evaluation_Framework/Evaluation_Datasets/semeval2007/semeval2007.gold.key.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_generator = model.prepare_sentence_batch(batch_size = 64,\n",
    "                                                     training_file_path = training_file_path_dev,\n",
    "                                                     gold_file_path = gold_file_path_dev,\n",
    "                                                     antivocab = antivocab,\n",
    "                                                     output_vocab = output_vocab,\n",
    "                                                     PADDING_SIZE = PADDING_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in validation_generator:\n",
    "    print(i.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind, row in enumerate(i):\n",
    "    print(ind, \"\\t\", row[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(iter):\n",
    "    try:\n",
    "        return len(iter)\n",
    "    except TypeError:\n",
    "        return sum(1 for _ in iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "306//64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_output_vocab[24].split(\":\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(wn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[reverse_output_vocab[q] for q in i[2,:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
